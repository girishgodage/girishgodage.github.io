<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.6">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-03-19T10:29:41+00:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Girish Godage</title><subtitle>I am a passionate Leader, who has a good command in technology &amp; Mangement. Also, I am a creative designer and an innovatie techie.</subtitle><author><name>Girish Godage</name></author><entry><title type="html">UPLOADING DOWNLOADING AND DELETING FILES IN AWS S3 CLOUD STORAGE USING ASP.NET CORE</title><link href="http://localhost:4000/blog/uploading-downloading-and-deleting-files-in-aws-s3-cloud-storage-using-asp-net-core" rel="alternate" type="text/html" title="UPLOADING DOWNLOADING AND DELETING FILES IN AWS S3 CLOUD STORAGE USING ASP.NET CORE" /><published>2021-03-10T05:54:00+00:00</published><updated>2021-03-10T05:54:00+00:00</updated><id>http://localhost:4000/blog/documentupload-in-S3-using-aspnetcore</id><content type="html" xml:base="http://localhost:4000/blog/uploading-downloading-and-deleting-files-in-aws-s3-cloud-storage-using-asp-net-core">## UPLOADING DOWNLOADING AND DELETING FILES IN AWS S3 CLOUD STORAGE USING ASP.NET CORE

This article will learn how to upload , download and delete files from amazon AWS S3 Cloud Storage using ASP.NET CORE.

## What is Amazon S3?

Amazon S3 has a simple web services interface that you can use to store and retrieve any amount of data, at any time, from anywhere on the web.

https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html

## What you'll be building

In this article, you'll learn the following

* Creating application ASP.NET Core Application
* Installing packages from NuGet
* Creating a Bucket
* View after creating a bucket.
* Creating a User
* Adding a User to Group and assigning policy
* Created Table for Storing Documents
* Added Entity and DbContext class along with interface and Concrete for Storing and Reading the documents
* AppSettings for Storing AccessKey and SecretKey  configuring database connection string
* Creating Controller
* Upload File
* AllFiles
* Download file
* Delete file

### Creating application ASP.NET Core Application

![image](/img/aspdotnetcore/1/01.png)

Next, we are going to set Project Name **“WebStorageDemo”** and location.

We will choose .Net Core framework and ASP.NET Core Version 5.0 as the framework for application and we are not going to enable docker settings for this project.

![image](/img/aspdotnetcore/1/02.png)

Now finally click on create button to create a project.

**Project structure**

The project structure generated according to the configuration.

![image](/img/aspdotnetcore/1/03.png)

After creating project next, we are going to install below package from NuGet Packages.

### Installing a package from NuGet

1. WindowsAzure.Storage

      ![image](/img/aspdotnetcore/1/04.png)

2. Microsoft.EntityFrameworkCore

      ![image](/img/aspdotnetcore/1/05.png)

3. Microsoft.EntityFrameworkCore.SqlServer

      ![image](/img/aspdotnetcore/1/06.png)

After installing packages next, we will create a bucket for that we must have an AWS account.


If you do not have an account, then create one account for free. https://aws.amazon.com/


I have already created an AWS account and logged in to the portal, for creating a bucket.
   

### Creating a Bucket

The bucket is a virtual container where we are going to store all objects.

For using Amazon S3 service, we must search S3 service in search.

![image](/img/aspdotnetcore/1/07.png)

After selecting S3 service, it redirects to buckets page.

![image](/img/aspdotnetcore/1/08.png)

Here for creating a bucket, we need to click on Create bucket button.

For creating a bucket, we need to enter a unique bucket name and select region where you want this bucket to be made.

![image](/img/aspdotnetcore/1/09.png)

Here we are going to enter the name of bucket **(myawscorebucket)** and then select region as “Asia Pacific (Mumbai)” after selecting just scroll your page then you will find **“Block Public Access settings for bucket”** here for the demo I am going to uncheck all checkboxes you must uncheck it according to your need.

![image](/img/aspdotnetcore/1/10.png)

Just scroll your page below you will find create bucket button just click on it to create a bucket.

![image](/img/aspdotnetcore/1/11.png)

### View after creating a bucket

![image](/img/aspdotnetcore/1/12.png)

After creating a bucket next, we are going to create a user for we need to search IAM **(Identity and Access Management).**

**Adding a User**

![image](/img/aspdotnetcore/1/13.png)

After selecting IAM, you will see below screen.

![image](/img/aspdotnetcore/1/14.png)

After clicking on Add user, we will add a user name and select Access type as shown below.

![image](/img/aspdotnetcore/1/15.png)

After filling in all details, click on the next permission button.

### Adding a User to Group and assigning policy

![image](/img/aspdotnetcore/1/16.png)

We will create a group with the name “AWSS3FullAccess” and assign policy (AmazonS3FullAccess) to access Amazon S3.

![image](/img/aspdotnetcore/1/17.png)

Just click on Create group button for creating a group. Next step will be making tags I will skip it, and the final screen will be Review as shown below.

![image](/img/aspdotnetcore/1/18.png)

The review page will show all details that you have configured just click on create a user it will create user successfully as shown below.

![image](/img/aspdotnetcore/1/19.png)

Now you have **Access key ID** and **Secret access key** for accessing S3 Services. Next, we have created a table in the database to store document details.

### Created Table for Storing Documents

Creating a table with name **DocumentStore** for storing document details.

![image](/img/aspdotnetcore/1/20.png)

Added Entity and DbContext class along with interface and Concrete for Storing and Reading the document.

![image](/img/aspdotnetcore/1/21.png)

In this part first, we have added the DocumentStore Entity.

```code

  using System;
  using System.ComponentModel.DataAnnotations;
  using System.ComponentModel.DataAnnotations.Schema;

  namespace WebStorageDemo.Models
  {
      [Table(&quot;DocumentStore&quot;)]
      public class DocumentStore
      {
          [Key]
          public int DocumentId { get; set; }
          public string DocumentName { get; set; }
          public string DocumentType { get; set; }
          public DateTime CreatedOn { get; set; }
      }
  }

```

Next, we have added DbContext with name BlobDbContext.

```code
  using Microsoft.EntityFrameworkCore;
  using WebStorageDemo.Models;

  namespace WebStorageDemo.Repository
  {
      public class BlobDbContext : DbContext
      {
          public BlobDbContext(DbContextOptions&lt;BlobDbContext&gt; options) : base(options)
          {
          }
          public DbSet&lt;DocumentStore&gt; DocumentStore { get; set; }
      }
  }
```

After adding BlobDbContext next, we are going to add Interface and Concrete in the Repository folder.

```code

  using System.Collections.Generic;
  using WebStorageDemo.Models;

  namespace WebStorageDemo.Repository
  {
      public interface IDocumentData
      {
          void Add(DocumentStore documentStore);
          List&lt;DocumentStore&gt; GetDocumentStoresList();
          void Delete(DocumentStore documentStore);
          DocumentStore GetDocumentbyDocumentId(int documentId);
      }
  }
```

AppSettings for Storing AccessKey and SecretKey and configuring database connection string

&gt; It is not recommended to store the keys in the appsettings.json file you can use the best methods available for the demo I am storing keys in the appsettings.json file.

![image](/img/aspdotnetcore/1/22.png)

After setting keys in the appsettings.json file next, we will configure entity framework core, appsettings and registering IDocumentData interface.

```code

public void ConfigureServices(IServiceCollection services)
{
    services.AddScoped&lt;IDocumentData, DocumentData&gt;();
    var connection = Configuration.GetConnectionString(&quot;DatabaseConnection&quot;);
    services.AddDbContext&lt;BlobDbContext&gt;(options =&gt; options.UseSqlServer(connection));
    services.Configure&lt;AppSettings&gt;(Configuration.GetSection(&quot;AwsSettings&quot;));
    services.AddControllersWithViews();
}

```

Everything is configured now let’s Create Controller for Uploading, Downloading and Deleting files.

### Creating Controller

We will create Controller With name **DemoController** with different action methods such as **UploadFile, DeleteFile, DownloadFile and AllFiles**.

**Upload File**

We will access 2 things in Controller AppSettings, IDocumentData from appsettings we will get bucket name, Access key and Secret key, we will pass Access key and Secret key to BasicAWSCredentials method and then set RegionEndpoint.

After that, we will get uploaded files details from **IFromFile** interface that we will assign to **TransferUtilityUploadRequest** class of AWS and then finally call **TransferUtility** class and access UploadAsync method to upload file meanwhile we are going to store all document details to the database.

```code
        [HttpGet]
        public IActionResult UploadFile()
        {
            return View();
        }

        [HttpPost]
        public async Task&lt;IActionResult&gt; UploadFile(IFormFile file)
        {
            try
            {

                var bucketName = !string.IsNullOrWhiteSpace(_appSettings.FolderName)
                    ? _appSettings.BucketName + @&quot;/&quot; + _appSettings.FolderName
                    : _appSettings.BucketName;

                var credentials = new BasicAWSCredentials(_appSettings.AccessKey, _appSettings.SecretKey);
                var config = new AmazonS3Config
                {
                    RegionEndpoint = Amazon.RegionEndpoint.APSouth1
                };


                using var client = new AmazonS3Client(credentials, config);
                await using var newMemoryStream = new MemoryStream();
                await file.CopyToAsync(newMemoryStream);

                var fileExtension = Path.GetExtension(file.FileName);
                var documentName = $&quot;{GenerateId()}{fileExtension}&quot;;

                // URL for Accessing Document for Demo
                var result = $&quot;https://{bucketName}.s3.amazonaws.com/{documentName}&quot;;

                var uploadRequest = new TransferUtilityUploadRequest
                {
                    InputStream = newMemoryStream,
                    Key = documentName,
                    BucketName = bucketName,
                    CannedACL = S3CannedACL.PublicRead
                };

                var fileTransferUtility = new TransferUtility(client);
                await fileTransferUtility.UploadAsync(uploadRequest);

                DocumentStore documentStore = new DocumentStore()
                {
                    CreatedOn = DateTime.Now,
                    DocumentId = 0,
                    DocumentName = documentName,
                    DocumentType = file.ContentType
                };

                _documentdata.Add(documentStore);

            }
            catch (AmazonS3Exception amazonS3Exception)
            {
                if (amazonS3Exception.ErrorCode != null
                    &amp;&amp; (amazonS3Exception.ErrorCode.Equals(&quot;InvalidAccessKeyId&quot;) || amazonS3Exception.ErrorCode.Equals(&quot;InvalidSecurity&quot;)))
                {
                    throw new Exception(&quot;Check the provided AWS Credentials.&quot;);
                }
                else
                {
                    throw new Exception(&quot;Error occurred: &quot; + amazonS3Exception.Message);
                }
            }
            return RedirectToAction(&quot;AllFiles&quot;);
        }

```

### Output

We are going to access the Demo/UploadFile path for uploading the file.

![image](/img/aspdotnetcore/1/23.png)

After uploading the file, we can see in AWS S3 objects section as shown below.

![image](/img/aspdotnetcore/1/24.png)

While uploading data, we are storing file details in the database.

![image](/img/aspdotnetcore/1/25.png)

### All Files

In this part, we are going to show all files which are stored in the database along with download and delete feature.

```code

  public IActionResult AllFiles()
    {
      return View(_documentdata.GetDocumentStoresList());
    }
```

![image](/img/aspdotnetcore/1/26.png)

### All Files View

```code

@model List&lt;DocumentStore&gt;

&lt;table class=&quot;table table-striped&quot;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;DocumentId&lt;/th&gt;
            &lt;th&gt;DocumentName&lt;/th&gt;
            &lt;th&gt;CreatedOn&lt;/th&gt;
            &lt;th&gt;Download&lt;/th&gt;
            &lt;th&gt;Delete&lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;

        @foreach (var data in Model)
        {
        &lt;tr&gt;
            &lt;td&gt;@data.DocumentId&lt;/td&gt;
            &lt;td&gt;@data.DocumentName&lt;/td&gt;
            &lt;td&gt;@data.CreatedOn&lt;/td&gt;
            &lt;td&gt;
                &lt;a class=&quot;btn btn-success&quot; href=&quot;/Demo/DownloadFile/@data.DocumentId&quot;&gt;Download&lt;/a&gt;
            &lt;/td&gt;
            &lt;td&gt;
                &lt;a class=&quot;btn btn-danger&quot; href=&quot;/Demo/DeleteFile/@data.DocumentId&quot;&gt;Delete&lt;/a&gt;
            &lt;/td&gt;
           
        &lt;/tr&gt;
        }
    &lt;/tbody&gt;
&lt;/table&gt;

```

### Download file

We have created the DownloadFile action method for downloading, which takes document id as an input parameter and then gets document details. From this document details, we will take document name and pass it to GetObjectAsync method, which will get an object from S3 Bucket which contains ResponseStream and objectResponse.Headers.ContentType.

```code
public async Task&lt;IActionResult&gt; DownloadFile(int id)
        {
            try
            {
                var getdocument = _documentdata.GetDocumentbyDocumentId(id);
                var credentials = new BasicAWSCredentials(_appSettings.AccessKey, _appSettings.SecretKey);
                var config = new AmazonS3Config
                {
                    RegionEndpoint = Amazon.RegionEndpoint.APSouth1
                };
                using var client = new AmazonS3Client(credentials, config);
                var fileTransferUtility = new TransferUtility(client);

                var objectResponse = await fileTransferUtility.S3Client.GetObjectAsync(new GetObjectRequest()
                {
                    BucketName = _appSettings.BucketName,
                    Key = getdocument.DocumentName
                });

                if (objectResponse.ResponseStream == null)
                {
                    return NotFound();
                }
                return File(objectResponse.ResponseStream, objectResponse.Headers.ContentType, getdocument.DocumentName);
            }
            catch (AmazonS3Exception amazonS3Exception)
            {
                if (amazonS3Exception.ErrorCode != null
                    &amp;&amp; (amazonS3Exception.ErrorCode.Equals(&quot;InvalidAccessKeyId&quot;) || amazonS3Exception.ErrorCode.Equals(&quot;InvalidSecurity&quot;)))
                {
                    throw new Exception(&quot;Check the provided AWS Credentials.&quot;);
                }
                else
                {
                    throw new Exception(&quot;Error occurred: &quot; + amazonS3Exception.Message);
                }
            }

        }
```

**Output**

![image](/img/aspdotnetcore/1/27.png)

### Delete file

For Deleting file, we have created a DeleteFile action method that takes document id as an input parameter and then documents details. From this document details, we will take document name and pass it to DeleteObjectAsync method which will delete an object from S3 Bucket while we are going call delete method from DocumentData class delete the file from the database.

```code
public async Task&lt;IActionResult&gt; DeleteFile(int id)
        {
            try
            {
                var getdocument = _documentdata.GetDocumentbyDocumentId(id);
                _documentdata.Delete(getdocument);

                var credentials = new BasicAWSCredentials(_appSettings.AccessKey, _appSettings.SecretKey);
                var config = new AmazonS3Config
                {
                    RegionEndpoint = Amazon.RegionEndpoint.APSouth1
                };
                using var client = new AmazonS3Client(credentials, config);
                var fileTransferUtility = new TransferUtility(client);
                await fileTransferUtility.S3Client.DeleteObjectAsync(new DeleteObjectRequest()
                {
                    BucketName = _appSettings.BucketName,
                    Key = getdocument.DocumentName
                });

            }
            catch (AmazonS3Exception amazonS3Exception)
            {
                if (amazonS3Exception.ErrorCode != null
                    &amp;&amp; (amazonS3Exception.ErrorCode.Equals(&quot;InvalidAccessKeyId&quot;) || amazonS3Exception.ErrorCode.Equals(&quot;InvalidSecurity&quot;)))
                {
                    throw new Exception(&quot;Check the provided AWS Credentials.&quot;);
                }
                else
                {
                    throw new Exception(&quot;Error occurred: &quot; + amazonS3Exception.Message);
                }
            }
            return RedirectToAction(&quot;AllFiles&quot;);
        }

```

**Before delete**

![image](/img/aspdotnetcore/1/28.png)

**After delete**

![image](/img/aspdotnetcore/1/29.png)

**Output**

![image](/img/aspdotnetcore/1/30.png)

## Summary

In this article, we have learned how to upload , download and delete files from amazon AWS S3 Cloud Storage using ASP.NET CORE in simple steps hope you have like it please share it let others learn from it.</content><author><name>Girish Godage</name></author><category term="learning" /><summary type="html">UPLOADING DOWNLOADING AND DELETING FILES IN AWS S3 CLOUD STORAGE USING ASP.NET CORE</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/img/aspnetcore.png" /></entry><entry><title type="html">How I choose which services to use in Azure</title><link href="http://localhost:4000/blog/how-i-choose-AzureService" rel="alternate" type="text/html" title="How I choose which services to use in Azure" /><published>2021-01-07T09:55:00+00:00</published><updated>2021-01-07T09:55:00+00:00</updated><id>http://localhost:4000/blog/how-i-choose-AzureService</id><content type="html" xml:base="http://localhost:4000/blog/how-i-choose-AzureService">## Introduction

Microsoft Azure is huge and changes fast! I’m impressed by the services and capabilities offered in Azure and by how quickly Microsoft releases new services and features. It can be overwhelming. There is so much out there — and the list continues to grow — it is sometimes hard to know which services to use for a given scenario.

I create Azure solutions for my customers, and I have a **method that I use to help me pick the right services**. This method helps me narrow down the services to choose from and pick the right ones for my solution. It helps me decide how to implement high-level requirements such as **“Running my application in Azure”** or **“Storing data for my application in Azure.”** 

![image info](/img/azure/12/img1.png)

Of course, these are just examples. There are many other categories to address when I’m architecting an Azure solution.

### A look at the process

Let me show you the process that I use for **“Running my application in Azure.”**


First, I try to answer several high-level questions, which in this case would be:

![image info](/img/azure/12/app_process.png)

  * **1. How much control do I need?**
  * **2. Where do I need my app to run?**
  * **3. What usage model do I need?**
  * **4. Which funcationality do I need?**

Once I’ve answered these questions, I’ve narrowed down the services from which to choose. And then, I look deeper into the services to see which one best matches the requirements of my application, including functionality as well as availability, performance, and costs.

Let’s go through the first part of the process where I answer the high-level questions about the category.

## Question 1: How much control do I need?

In considering how much control I need, I try to figure out the degree of control I need over the **operating system, load balancers, infrastructure, application scaling,** and so on. This decides the category of services that I will be selecting from.

On the control side of the spectrum is **infrastructure-as-a-service (IaaS)** category, which includes services like [Azure Virtual Machines](https://azure.microsoft.com/services/virtual-machines/) and [Azure Container Instances](https://azure.microsoft.com/services/container-instances/). These give a lot of control over the operating system and the infrastructure that runs your application. But with &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;**control comes great responsibility**&lt;/span&gt;. For instance, if you control the operating system, you are responsible to update it and make sure that it is secure.

![image info](/img/azure/12/How_much_control.png)
*Figure 1. How much control do I need?*


Further up the stack are services that fall into the **platform-as-a-service (PaaS)** category, which contains services like [Azure App Service Web Apps](https://azure.microsoft.com/services/app-service/web/). In PaaS, you don’t have control over the operating system that your application runs on, nor are you responsible for it. You do have control over scaling your application and your application configuration (e.g., the version of .NET you want your application to run on.

The next abstraction level is what I will here call **logic as a service (LaaS)**, also known as **serverless**. This category contains services like [Azure Functions](https://azure.microsoft.com/services/functions/) and [Azure Logic Apps](https://azure.microsoft.com/services/logic-apps/). Here, Azure takes care of the underlying infrastructure for you, including scaling your app. Logic as a service gives little control over the infrastructure that your application runs on, which means that you are only responsible for creating the application itself and configuring its application settings, like connection strings to databases.

The highest level of abstraction is **software as a service (SaaS)**, which offers the least amount of control and the most amount of time that you can focus on working on business value. An example of Azure SaaS is [**Azure Cognitive Services**](https://azure.microsoft.com/services/cognitive-services/), which are APIs that you just call from your application. Somebody else owns their application code and infrastructure; you just consume them. And all you manage is basic application configuration, like managing the API keys that you use to call the service.

Once I know how much control I need, I can pick the category of services in Azure and narrow down my choice.

## Question 2: Where do I need my app to run?

The second question stemming from “Running my application in Azure” is: Where do I need my application to run?

![image info](/img/azure/12/Where-my-app-run.png)
*Figure 2. Where do I need my app to run?*

You might think that the answer would be: I need to run my application in Azure. But the answer may not be that simple. For example, maybe I do want parts of my application to run in the Azure public cloud but I want to run other parts in [Azure Government](https://azure.microsoft.com/global-infrastructure/government/) or the Azure China cloud or even on-premises using [Azure Stack](https://azure.microsoft.com/overview/azure-stack/).

Or it could be that I want to be able run my application in Azure and on-premises (if rules and regulations change), on my local development computer, or even in public clouds from other vendors.

This question boils down to how vendor-agnostic I’d like to be and where to store my data.

Once I’ve answered this question, I can narrow down the choice of Azure services even further.

## Question 3: What usage model do I need?

How my app will be used guides me to the answer to the third and final question: what usage model do I need?

![image info](/img/azure/12/What-useage-model.png)
*Figure 3. What usage model do I need?*

Some applications **are in use all the time**, like a website. If that is the case for my application, I need to look for services that run on what I call the **classic model**. This means that they are always running and that you pay for them all month.

Other applications **are only in use occasionally**, like a background job that runs once every hour, or an API that handles order cancellations (called a few times a day). If my application runs occasionally, I need to select a service from the logic-as-a-service (or serverless) category. These services only run when you need them, and you only pay for them when they run.

After I’ve answered the high-level questions for this category, I can narrow down the services that I can choose from to just a couple or even one.

## Question 4: Which functionality do I need?

In this step: We match service functionality to my application requirements

Now, I need to figure out which service fulfills the most requirements for my application. I do so by looking at the functionality that I need, the availability that the service offers in its service level agreement, the performance that it provides, and what it costs.

Finally, this leads me to the service that I want to use to run my application. Often, I use multiple services to run my application, because it consists of many pieces, like a user interface and APIs. So, it might turn out that I run my web application in an Azure App Service Web App and my APIs in Azure Functions.

## Example : 

So, let's just try this out.I have an app, and **I trust Azure to scale for me**.I don't want to do that myself, **My app needs to run in Azure and on-premises as well**.**As my app only needs to run once every hour**, so not all the time.

My Need to run App.

* **I trust Azure to scale for me**
* **My app needs to run in Azure and on-premises as well**
* **My app only needs to run once every hour**

So let's see. These are all the options currently.They're out there in Azure to run my application.

![image info](/img/azure/12/Options_For_Running_App.png)
**Figure:Option for running Apps on Azure**

So, for example, I'm thinking,well, I could just put it into VM,it could be fine, but then I'm paying 24/7 all the time.

&gt; But My app need are it doesn't have to be always on.

I have to remote it to desktop,I have to access or SSH into it and upgrade it.I have to maintain the security.

&gt; But My app need are Azure to Scale it.

So, probably not a VM.

Exacty, So, services in the category into infrastructure as a service category,those are not the services that I want in this case.

Also services in the platform as a service category those also need scaling instructions, let's say.Azure doesn't do that automatically for me.Yes I can obviously have automatic scaling in a web app,but still I need to think about that and I need to configure it myself.And I don't want that for this app.

And even I could do Kubernetes and have that scale, but it will be running all the time. 

So, I end up in the last category and that is I call it logic Azure service or serverless,and that could be functions or logic apps for instance.
So that's one category that we've drilled down to. 

![image info](/img/azure/12/img2.png)

So, that ends up in me being able to work a lot on the business value,and not so much having to worry about the plumbing and infrastructure of a VM for instance.

So, the next thing is,**I want to Stay Vendor Agnostic**. That's what I said because **it needs to run in Azure but also on premises**. 

So, I don't want to opt in for Azure completely.it needs to run anywhere.In that case, I can choose from these services

![image info](/img/azure/12/img3.png)

including Azure functions because,Azure functions run on the Azure functions run-time.I can run that anywhere basically. 

I can take Azure functions as a docker container that I can build from and I could put that on anywhere, on a container locally On-premise Or on my own laptop.Wherever. So, that's still an options in this case.


Then the next one is I only want to run it occasionally.So not all the time.That's the serverless,those are Azure Batch,Logic apps and Azure functions.

![image info](/img/azure/12/img4.png)

So, I'm kind of drilling down to Azure functions in this case.For this particular app needs.

Then I will compare all the features of the Azure services to the requirements that I have.I'm not going to drill down into that right now,but I just wanted to show you that I do that in different tables like these.

And I don't just build a big table,where I just put in all of the Azure services,but just tables that compare one category to another.

For instance, these are all the services for container options and VMs,

&lt;span style=&quot;color:yellow;background-color:black;&quot;&gt; **Below are the comparision Chart for quick reference**&lt;/span&gt;

![image info](/img/azure/12/img5.png)

and these are all the services for background tasks, will be the one that I need.

![image info](/img/azure/12/img6.png)

And these are all the services for running your application in Azure.

![image info](/img/azure/12/img7.png)

So, that's my process for choosing how to run an application in Azure.And now the next part is,**how do I store my data in Azure?**

## Storing Data in Azure

![image info](/img/azure/12/storing_data.png)

 
&gt; The process that I use for “Storing Data in Azure.”


How do I do that? Again the same thing.I have a couple of big picture questions that asks to narrow down to services.


![image info](/img/azure/12/storing_data_question.png)

* **What will I use the data for?**
* **What type of data am I going to store?**
* **Which functionality do I need?**

Once I’ve answered these questions, I’ve narrowed down the services from which to choose. And then, I look deeper into the services to see which one best matches the requirements of my application, including functionality as well as availability, performance, and costs.

## Question 1: What will I use the data for?

So, what will I use the data for? Is it for my application? 

So actually for my application,where I have a data stored on my website for instance that stores customer records or something,that's also called **Online Transactional Processing**.

The other usage that you can imagine is for data analytics, we do reporting.And that's called **Online Analytical Processing**.

![image info](/img/azure/12/What_will_I_use_data_for.png)

So that's the first divide that we do.

## Question 2: What type of data am I going to store?

There are lots of data types.One is Relational Data,another one is Unstructured Data.There are semi-structure data and all that stuff but we're just going to stick to
these for clarity and simplicity.

In unstructured Data you have different types: Document Data,key Value Data, and Graph Data as well.

![image info](/img/azure/12/What_type_of_data.png)


And then we're going to try it out,Here is my application data need

* **My app is an online reservation system**.

* **My app needs to store and retrieve document data.**

So that last sentence actually says it all.

For this example, we're going to focus on the store and retrieve document data in the application.

So, this is again an example of all of the services that are out there right now in Azure for storing data.

![image info](/img/azure/12/Options_for_storing_data.png)

These are things like Azure Sequel Database,Azure storage but also Azure sequel data warehouse.

So the first thing that we're going to do,is divide this into two categories of data usage.

![image info](/img/azure/12/data_category.png)

So Online Transactional Processing,
so the data storage that I actually
use for my application,
and Online Analytical Processing
data storage that I use for reporting.

So, in our case, it falls into the **first category**,because I want to store and retrieve data for my online reservation system that is online constantly.

And then the second one is, **what type of data**?

So again, these services are relational data,

![image info](/img/azure/12/Relational_data.png)

and these services I can store unstructured or document data and all the other sub types of that.

![image info](/img/azure/12/Unstructure_data.png)

and then these services as a Sequel data warehouse and data lakes store.
I can do data analytics,so I can store big chunks of data and use things like
Power BI or Hadoop Clusters actually crunched that data.

![image info](/img/azure/12/data_analytic.png)

And then after that, I would go into these tables,just like I did for the running the applications,and to see if the requirements match the functionality of the services.

![image info](/img/azure/12/data_compare.png)

And again, I compare services in
different categories like for OLAP and OLTP in this case.

![image info](/img/azure/12/data_compare1.png)

So that's my process basically.

So, these were just a couple
of services in the Azure space,
just for running your application and for storing data.

Obviously, there are lot of more services out there for securing your application and for doing IoT and all that stuff.</content><author><name>Girish Godage</name></author><category term="learning" /><summary type="html">Introduction</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/img/azure/12/img1.png" /></entry><entry><title type="html">Facebook Authentication And Authorization In Server-Side Blazor App</title><link href="http://localhost:4000/blog/facebook-authentication-and-authorization-in-server-side-blazor-app" rel="alternate" type="text/html" title="Facebook Authentication And Authorization In Server-Side Blazor App" /><published>2020-12-20T09:46:00+00:00</published><updated>2020-12-20T09:46:00+00:00</updated><id>http://localhost:4000/blog/facebook-authentication-and-authorization-in-server-side-blazor-app</id><content type="html" xml:base="http://localhost:4000/blog/facebook-authentication-and-authorization-in-server-side-blazor-app">## Introduction

In this article, we will learn how to implement authentication and authorization using Facebook in a server-side Blazor application.

## Prerequisites
  * Install the latest .NET Core 5.0 Current  SDK from [here](https://dotnet.microsoft.com/download/dotnet-core/).
  * Install the latest Visual Studio 2019 from [here](https://visualstudio.com/).
  
## Source Code

Get the source code from [GitHub](https://github.com/girishgodage/Facebook-Authentication-with-server-side-Blazor).

## Create Server Side Blazor Application

To create a server-side Blazor app, open Visual Studio 2019 and follow the steps mentioned below:

    1. Click on “Create a new project”.
    2. Select “Blazor App” from available project types. Click on Next.
    3. A new “Configure your new project” screen will open. Put the name of the project as BlazorFbAuth and click Create.
    4. In the next screen, select “.NET.5.0 ” from dropdowns on the top left.
    5. Select “Blazor Server App” from the list of available templates.
    6. Click on Change Authentication button, a “Change Authentication” dialog box will open.
    7.Select “Individual User Account” and click OK. Click on Create button to create the application.

These steps are shown in the GIF image below.

![image info](/img/blazor/5/CreateProject.gif)


Before running the application, we need to apply migrations to our app. Navigate to Tools &gt;&gt; NuGet Package Manager &gt;&gt; Package Manager Console.

It will open the Package Manager Console. Put in **Update-Database** command and hit enter. This will update the database using Entity Framework Code First Migrations.

![image info](/img/blazor/5/UpdateDatabase.png)

Right-click on the project in solution explorer and select properties. Select Debug from left side menu then scroll to the bottom of the page. Note the SSL enabled URL. In this case, the URL is https://localhost:44345/. We need this URL to configure the Facebook app which we will be doing in our next section. Refer to the image below.

![image info](/img/blazor/5/AppURL.png)

## Creating a Facebook App

We need to create a Facebook app and configure Facebook Login for it. We will then use the App ID and App Secret of this Facebook app to implement Facebook authentication in our Blazor app. Navigate to https://developers.facebook.com/apps/ and sign in using your Facebook account. Follow the steps mentioned below.

 * Click on the “Create App” button under the “My Apps” menu on the top.
 * It will open a “Create a New App ID” dialog box. Put in the “Display Name” and “Contact Email”.
 * The default email will be your Facebook email id. However, you can change it and put any email of your choice. Click on “Create App ID” to create the app. Refer to the image below.

![image info](/img/blazor/5/BlazorFBAuthAppInfo.png)

 * Navigate to the app dashboard by clicking on the “Dashboard” link on the navigation menu on the left.
 * Under the “Add a Product” section, select the “Facebook Login” product and click on “Set Up” button.
 * A QuickStart wizard will be launched asking you to select a platform for the app. Skip this wizard and click on Facebook Login &gt; Settings from the navigation menu on the left.
 * You will be navigated to the Client OAuth Settings page. In the Valid OAuth redirect URIs field enter the base URL of your application with /signin-facebook appended to it. For this tutorial, the URL will be https://localhost:44345/signin-facebook. Click on “Save Changes” button.
 * Now click on Settings &gt; Basic on the navigation menu. You will see the App ID and App Secret values. Make a note of these values as we need them to configure Facebook authentication in our Blazor app.
  

Refer to the GIF below for a better understanding.

![image info](/img/blazor/5/FBSettings.gif)


## Important Note

&gt; The trademark or brand element of Facebook is not allowed to be used as the Display Name of your Facebook App. Therefore, words such as FB, Face, Book, Insta, etc. cannot be used as Display Name.


## Installing Facebook authentication middleware NuGet package

To configure the ASP.NET Core middleware for Facebook authentication we need to install the nuget package in our application. The version of this nuget package must match the version of .NET Core 3 which we are using in our project.

Open https://www.nuget.org/packages/Microsoft.AspNetCore.Authentication.Facebook/. Select the version of .NET 5.0.1 from the “Version History”. Copy the command from the “package manager” tab. Run this command in the NuGet package manager console of our application.

For this application, we are using .NET 5.0.1. Therefore, we will run the following command in the package manager console of our application.

```code
    Install-Package Microsoft.AspNetCore.Authentication.Facebook -Version 5.0.1
```

Refer to the image below:

![image info](/img/blazor/5/InstallFBAuthentication.png)

## Configure the server-side Blazor app to use Facebook authentication

We need to store the App ID and App Secret field values in our application. We will use Secret Manager tool for this purpose. The Secret Manager tool is a project tool that is used to store secrets such as password, API Key, etc. for a .NET Core project during the development process. Secret Manager tool allows us to associate app secrets with a specific project. It also allow us to share them across multiple projects.

Open our web application once again and Right-click the project in Solution Explorer. Select Manage User Secrets from the context menu. A secrets.json file will open. Put the following code in it.

```code
    {
        &quot;Authentication:Facebook:AppId&quot;: &quot;Your Facebook AppId&quot;,
        &quot;Authentication:Facebook:AppSecret&quot;: &quot;Your Facebook AppSecret&quot;
    }
```

Now open Startup.cs file and put the following code into ConfigureServices method.

```code

    services.AddAuthentication().AddFacebook(facebookOptions =&gt;
    {
        facebookOptions.AppId = Configuration[&quot;Authentication:Facebook:AppId&quot;];
        facebookOptions.AppSecret = Configuration[&quot;Authentication:Facebook:AppSecret&quot;];
        facebookOptions.Events = new OAuthEvents()
        {
            OnRemoteFailure = loginFailureHandler =&gt;
            {
            var authProperties = facebookOptions.StateDataFormat.Unprotect(loginFailureHandler.Request.Query[&quot;state&quot;]);
            loginFailureHandler.Response.Redirect(&quot;/Identity/Account/Login&quot;);
            loginFailureHandler.HandleResponse();
            return Task.FromResult(0);
            }
        };
    });
```

This code will read the AppId and AppSecret from the secrets.json file. The AddFacebook() method is an extension method and it is used to configure the Facebook Authentication options for our application. We are also handling the event of OnRemoteFailure in this code section. Hence, if the user denies access to his Facebook account, then he will be redirected back to the Login page of our Blazor application.

## Adding authorization to Blazor pages

Blazor has added a new built-in component called AuthorizeView. This component is used to display different content based on the authentication state of the application. This component will display the child component only when the user is authorized.  The AuthorizeView component is configured in \Shared\LoginDisplay.razor file.

To implement authorization to a specific page, we need to use the [Authorize] attribute. Blazor has introduced a new directive @attribute, which is used to include the [Authorize] attribute for a page. In this application, we will apply [Authorize] to the FetchData component. This will prohibit unauthorized access to this component. Open FetchData.razor page and add the following lines at the top of the page.

```code

@attribute [Authorize]

```

## Execution Demo

Launch the application. Navigate to Fetch Data component by clicking on the “Fetch data” link on the menu on the left. You will see a “Not authorized” message displayed on the screen. Click “Log In” on the menu at the top. In the next page click on the “Facebook” button to login with Facebook. On the next page, you will be asked to provide the login credentials of your Facebook account. Fill the details and click Log In. Upon successful login, you will be able to access the Fetch Data component. If you do not want to login then click on “Not now”. It will redirect you back to the Login page of Blazor app.

Refer to the GIF below for a better understanding.

![image info](/img/blazor/5/output.gif)

Once you are logged in successfully into our Blazor app using Facebook, you will be also logged in to https://www.facebook.com/. This will create a set of browser cookie for https://www.facebook.com/. Therefore, the Blazor app will not ask the Facebook credentials when you try to login again. If you log out from Facebook then you have to enter credentials while logging into Blazor app.

## Conclusion

We learned how to implement Facebook authentication and authorization in a server-side Blazor application. We have created and configured a Facebook app to implement Facebook authentication. To implement authorization for a specific component in Blazor, we have used the [Authorize] attribute. We have used Microsoft.AspNetCore.Authentication.Facebook nuget package to configure the middleware for Facebook authentication.

Please get the source code from [GitHub](https://github.com/girishgodage/Facebook-Authentication-with-server-side-Blazor) and play around to get a better understanding.</content><author><name>Girish Godage</name></author><category term="learning" /><summary type="html">Introduction</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/img/blazor/5/output.gif" /></entry><entry><title type="html">How to Deploy Angular Application to Heroku</title><link href="http://localhost:4000/blog/how-to-deploy-angular-application-to-heroku" rel="alternate" type="text/html" title="How to Deploy Angular Application to Heroku" /><published>2020-12-20T09:46:00+00:00</published><updated>2020-12-20T09:46:00+00:00</updated><id>http://localhost:4000/blog/deploy-angular-on-Heroku</id><content type="html" xml:base="http://localhost:4000/blog/how-to-deploy-angular-application-to-heroku">## Introduction

It has always ‘seemed’ easy until you try it. Having deployed other apps to heroku, I encountered series of challenges deploying Angular 11 recently but I pulled through finally. So am writing to explain in details how I did it.

This article will show you guides on deploying your Angular 8/9/10/11 apps easily to Heroku, more importantly, avoiding common pitfalls.

This is not a tutorial to help you learn Angular. It will be assumed you have completed development and ready to deploy. However, we’ll setup basic angular project from start and deploy. This tutorial will cover:

  * Creating basic angular project
  * Setting automatic deployment from GitHub to Heroku
 * Deploying Angular app on Heroku server


## Setup Your Angular Application
Making use of the Angular CLI, setup a new project by running:
```code

    ng new demo-deploy

```

![image info](/img/deployment/1/CreateAngularApp.png)

From this, our application will be named demo-deploy . Allow for few minutes to setup the new project and install npm packages.

## Launch Application

Change directory into new project and launch it using the commands below. This will open in new browser on port 4200 by default. i.e http://localhost:4200.

```code
cd demo-deploy
ng serve

```

![image info](/img/deployment/1/angularapp.png)


Our basic angular app is ready and running — locally. Lets push to github

## Create its GitHub repo and Push
Here, we’ll be creating a fresh github repository and pushing our app to it.

  * Login to github and create new repository. No need to initialize repository with README

  * Open new tab in your terminal/CMD. Or hit Ctrl+C to stop running app. Then run the following commands:

```code 

    git remote add origin &lt;new_github_repository_url&gt;
    git add --all
    git commit -m &quot;initial commit&quot;
    git push -u origin master

```

Now our app is on github.

## Setup Automatic Deployment from GitHub to Heroku

Advantage of this step is so that, once you push a change to your github repository, it automatically pushes the change to your codebase on heroku, which then takes effect live on the web. This means, you’ll only have to push your changes to github and its done.

If you dont have an account yet, create one on heroku website. Its free. Login to your dashboard and create a new app.

![image info](/img/deployment/1/CreateHerokuapp.png)

Click Create app

In the Deploy menu, under Deployment method, select GitHub. If you have not done this already, it will ask you to login your github account so it can connect to it.

Enter the name of the GitHub repository and click Search. Once the repo is shown below, click Connect. Viola!

![image info](/img/deployment/1/HerokuGithubConnect.png)

Uh, wait. Two more simple steps.

  1. Under Automatic Deploys, select the master branch and click Enable Automatic Deploys.
   
  2. Under Manual Deploys, click Deploy Branch. This is to push our fresh code to heroku.

![image info](/img/deployment/1/EnableAutoDeploy.png)

Okay, we’r done with this stage really. It might take a little while but will show you successfully deployed message once done, like so:

![image info](/img/deployment/1/DeployGithubBranch.png)

![image info](/img/deployment/1/DeployError.png)

If you click View, a new tab will be opened but your app will not display. Next series of steps will guide you on configuring and spinning up your angular app.

## Configure Your Angular App to Deploy Properly on Heroku

The following are production-ready steps to easily and properly deploy your app without hitches.

&gt; **Ensure you have the latest version of angular cli and angular compiler cli**.

Install them into your application by running this commands in your terminal:

```code
npm install @angular/cli@latest @angular/compiler-cli --save-dev

```

In your package.json, copy

```code 

&quot;@angular/cli”: “~11.0.5”,
&quot;@angular/compiler-cli&quot;: &quot;~11.0.5&quot;,

```

from devDependencies to dependencies

## Create postinstall script in package.json

Under “scripts”, add a “heroku-postinstall” command like so:

```code 
&quot;heroku-postbuild&quot;: &quot;ng build --aot --prod &quot;

```

This tells Heroku to build the application using Ahead Of Time (AOT) compiler and make it production-ready. This will create a dist folder where all html and javascript converted version of our app will be launched from.

## Add Node and NPM engines

You will need to add the Node and NPM engines that Heroku will use to run your application. Preferably, it should be same version you have on your machine. So, run *node -v* and *npm -v* to get the correct version and include it in your package.json file like so:

```code 

    &quot;engines&quot;: {
    &quot;node&quot;: &quot;15.2.0&quot;,
    &quot;npm&quot;: &quot;7.0.12&quot;
  }

```

## Copy typescript to dependencies.

Copy &quot;typescript&quot;: &quot;~4.0.2&quot; from devDependencies to dependencies to also inform Heroku what typescript version to use.

## Install Enhanced Resolve 3.3.0

Run the command **npm install enhanced-resolve@3.3.0 --save-dev**

## Install Server to run your app

Locally we run ng serve from terminal to run our app on local browser. But we will need to setup an Express server that will run our production ready app (from dist folder created) only to ensure light-weight and fast loading.

Install Express server by running:

```code 

npm install express path --save

```

Create a server.js file in the root of the application and paste the following code.

```code 

    //Install express server
    const express = require('express');
    const path = require('path');

    const app = express();

    // Serve only the static files form the dist directory
    app.use(express.static(__dirname + '/dist/&lt;name-of-app&gt;'));

    app.get('/*', function(req,res) {
        
    res.sendFile(path.join(__dirname+'/dist/&lt;name-of-app&gt;/index.html'));
    });

    // Start the app by listening on the default Heroku port
    app.listen(process.env.PORT || 8080);

```

## Change start command

In package.json, change the “start” command to node server.js so it becomes:

```code 

    &quot;start&quot;: &quot;node server.js&quot;

```

Here’s what the complete package.json looks like. Yours may contain more depending on your application-specific packages.

```code 

{
  &quot;name&quot;: &quot;demo-deploy&quot;,
  &quot;version&quot;: &quot;0.0.0&quot;,
  &quot;scripts&quot;: {
    &quot;ng&quot;: &quot;ng&quot;,
    &quot;start&quot;: &quot;node server.js&quot;,
    &quot;build&quot;: &quot;ng build&quot;,
    &quot;test&quot;: &quot;ng test&quot;,
    &quot;lint&quot;: &quot;ng lint&quot;,
    &quot;e2e&quot;: &quot;ng e2e&quot;,
    &quot;heroku-postbuild&quot;: &quot;ng build --aot --prod &quot;
  },
  &quot;private&quot;: true,
  &quot;dependencies&quot;: {
    &quot;@angular/animations&quot;: &quot;~11.0.5&quot;,
    &quot;@angular/cdk&quot;: &quot;^11.0.3&quot;,
    &quot;@angular/cli&quot;: &quot;~11.0.5&quot;,
    &quot;@angular/common&quot;: &quot;~11.0.5&quot;,
    &quot;@angular/compiler&quot;: &quot;~11.0.5&quot;,
    &quot;@angular/compiler-cli&quot;: &quot;~11.0.5&quot;,
    &quot;@angular/core&quot;: &quot;~11.0.5&quot;,
    &quot;@angular/forms&quot;: &quot;~11.0.5&quot;,
    &quot;@angular/platform-browser&quot;: &quot;~11.0.5&quot;,
    &quot;@angular/platform-browser-dynamic&quot;: &quot;~11.0.5&quot;,
    &quot;@angular/router&quot;: &quot;~11.0.5&quot;,
    &quot;express&quot;: &quot;^4.17.1&quot;,
    &quot;path&quot;: &quot;^0.12.7&quot;,
    &quot;rxjs&quot;: &quot;~6.6.0&quot;,
    &quot;tslib&quot;: &quot;^2.0.0&quot;,
    &quot;typescript&quot;: &quot;~4.0.2&quot;,
    &quot;zone.js&quot;: &quot;~0.10.2&quot;
  },
  &quot;devDependencies&quot;: {
    &quot;@angular-devkit/build-angular&quot;: &quot;~0.1100.5&quot;,
    &quot;@angular/cli&quot;: &quot;~11.0.5&quot;,
    &quot;@angular/compiler-cli&quot;: &quot;~11.0.5&quot;,
    &quot;@types/googlemaps&quot;: &quot;3.39.14&quot;,
    &quot;@types/jasmine&quot;: &quot;~3.6.0&quot;,
    &quot;@types/node&quot;: &quot;^12.11.1&quot;,
    &quot;codelyzer&quot;: &quot;^6.0.0&quot;,
    &quot;enhanced-resolve&quot;: &quot;^3.3.0&quot;,
    &quot;jasmine-core&quot;: &quot;~3.6.0&quot;,
    &quot;jasmine-spec-reporter&quot;: &quot;~5.0.0&quot;,
    &quot;karma&quot;: &quot;~5.1.0&quot;,
    &quot;karma-chrome-launcher&quot;: &quot;~3.1.0&quot;,
    &quot;karma-coverage&quot;: &quot;~2.0.3&quot;,
    &quot;karma-jasmine&quot;: &quot;~4.0.0&quot;,
    &quot;karma-jasmine-html-reporter&quot;: &quot;^1.5.0&quot;,
    &quot;protractor&quot;: &quot;~7.0.0&quot;,
    &quot;ts-node&quot;: &quot;~8.3.0&quot;,
    &quot;tslint&quot;: &quot;~6.1.0&quot;,
    &quot;typescript&quot;: &quot;~4.0.2&quot;
  },
  &quot;engines&quot;: {
    &quot;node&quot;: &quot;15.2.0&quot;,
    &quot;npm&quot;: &quot;7.0.12&quot;
  }
}

```

Push changes to GitHub:

```code

    git add .
    git commit -m &quot;updates to deploy to heroku&quot;
    git push  

```

At this point, your application on Heroku will automatically take the changes from GitHub and update itself.

Also, it’ll look into your package.json and install packages.

It will run the postinstall and then, *node server.js* to spin up your application.

You can check Activity tab and open Build log to see how it actually runs.

You should not run into any issue. I followed through while writing this post also and.

Viola!! Our Angular app is Ready and LIVE!

![image info](/img/deployment/1/DeployedApp.png)

For following through till this stage, Thank you.

Provide your valuable comment below, also if you encountered any issue or want to suggest better ways.</content><author><name>Girish Godage</name></author><category term="learning" /><summary type="html">Introduction</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/img/deployment/1/AnularDeployHeroku.png" /></entry><entry><title type="html">Multi-Language Translator Using Blazor And Azure Cognitive Services</title><link href="http://localhost:4000/blog/multi-Language-Translator-using-blazor-AzureCognitiveServices" rel="alternate" type="text/html" title="Multi-Language Translator Using Blazor And Azure Cognitive Services" /><published>2020-12-17T16:55:00+00:00</published><updated>2020-12-17T16:55:00+00:00</updated><id>http://localhost:4000/blog/multi-language-translator-using-blazor-and-azure-cognitive-service</id><content type="html" xml:base="http://localhost:4000/blog/multi-Language-Translator-using-blazor-AzureCognitiveServices">## Introduction

In this article, we will create a multilanguage translator using Blazor and the Translate Text Azure Cognitive Service. This translator will be able to translate between all the languages supported by the Translate Text API. Currently, the Translate Text API supports more than 60 languages for translation. The application will accept the text to translate and the target language as the input and returns the translated text and the detected language for the input text as the output.

Take a look at the output shown below.

![image info](/img/azure/11/output.gif)

## Prerequisites
  * Install the latest .NET Core 3.1 SDK from https://dotnet.microsoft.com/download/dotnet-core/3.1
  * Install the latest version of Visual Studio 2019 from https://visualstudio.microsoft.com/downloads/
 * An Azure subscription account. You can create a free Azure account  at https://azure.microsoft.com/en-in/free/


## Source Code
You can get the source code from [GitHub](https://github.com/girishgodage/Blazor-Translator-Azure-Cognitive-Services).

## Create the Azure Translator Text Cognitive Services resource

Log in to the Azure portal and search for the cognitive services in the search bar and click on the result. Refer to the image shown below.

![image info](/img/azure/9/SearchCognitive.png)

On the next screen, click on the Add button. It will open the cognitive services marketplace page. Search for the Translator Text in the search bar and click on the search result. It will open the Translator Text API page. Click on the Create button to create a new Translator Text resource. Refer to the image shown below.

![image info](/img/azure/11/CreateTranslatorService.png)


On the Create page, fill in the details as indicated below.

  * **Name**: Give a unique name for your resource.
  * **Subscription**: Select the subscription type from the dropdown.
  * **Pricing tier**: Select the pricing tier as per your choice.
  * **Resource group**: Select an existing resource group or create a new one.

Click on the Create button. Refer to the image shown below.

![image info](/img/azure/11/CreateTranslatorService_1.png)

![image info](/img/azure/11/CreateTranslatorService_2.png)


After your resource is successfully deployed, click on the “Go to resource” button. You can see the Key and the endpoint for the newly created Computer Vision resource. Refer to the image shown below.

![image info](/img/azure/11/TranslatorKeyNEndPoint.png)


Make a note of the **key**, we will be using this in the latter part of this article to request the translations from the Translator Text API. The values are masked here for privacy.

## Create a Server-Side Blazor Application

Open Visual Studio 2019, click on “Create a new project”. Select “Blazor App” and click on the “Next” button. Refer to the image shown below.

![image info](/img/azure/10/Create_BlazorApp.png)

On the next window, put the project name as &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;BlazorTranslator&lt;/span&gt; and click on the “Create” button. The next window will ask you to select the type of Blazor app. Select &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;Blazor Server App &lt;/span&gt; and click on the Create button to create a new server-side Blazor application. Refer to the image shown below.

![image info](/img/azure/10/Create_BlazorApp_1.png)


## Create the Models

Right-click on the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;BlazorTranslator&lt;/span&gt; project and select Add &gt;&gt; New Folder. Name the folder as Models. Again, right-click on the Models folder and select Add &gt;&gt; Class to add a new class file. Put the name of your class as &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;LanguageDetails.cs&lt;/span&gt; and click Add.

Open &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;LanguageDetails.cs&lt;/span&gt; and put the following code inside it.

```code
 namespace BlazorTranslator.Models
{
    public class LanguageDetails
    {
        public string Name { get; set; }
        public string NativeName { get; set; }
        public string Dir { get; set; }
    }
}

```

Similarly, add a new class file &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;TestResult.cs &lt;/span&gt; and put the following code inside it.

```code
 using System;
namespace BlazorTranslator.Models
{
    public class TextResult
    {
        public string Text { get; set; }
        public string Script { get; set; }
    }
}

```

Add a new class file Translation.cs and put the following code inside it.

```code

    namespace BlazorTranslator.Models
    {
        public class Translation
        {
            public string Text { get; set; }
            public TextResult Transliteration { get; set; }
            public string To { get; set; }
        }
    }

```

Create a class file &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;DetectedLanguage.cs&lt;/span&gt; and put the following code inside it.

```code
    namespace BlazorTranslator.Models
    {
        public class DetectedLanguage
        {
            public string Language { get; set; }
            public float Score { get; set; }
        }
    }

```

Create a class file &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;TranslationResult.cs&lt;/span&gt; and put the following code inside it.

```code

    namespace BlazorTranslator.Models
    {
        public class TranslationResult
        {
            public DetectedLanguage DetectedLanguage { get; set; }
            public TextResult SourceText { get; set; }
            public Translation[] Translations { get; set; }
        }
    }

```

Finally, create the class file &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;AvailableLanguage.cs&lt;/span&gt; and put the following code inside it.

```code
    using System.Collections.Generic;
    namespace BlazorTranslator.Models
    {
        public class AvailableLanguage
        {
        public Dictionary&lt;string, LanguageDetails&gt; Translation { get; set; }
        }
    }

```

## Create the Translation service

Right-click on the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;BlazorTranslator/Data&lt;/span&gt; folder and select Add &gt;&gt; Class to add a new class file. Put the name of the file as &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;TranslationService.cs&lt;/span&gt; and click on Add. Open &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;TranslationService.cs&lt;/span&gt; file and put the following code inside it.

```code

    using BlazorTranslator.Models;
    using Newtonsoft.Json;
    using System;
    using System.Net.Http;
    using System.Text;
    using System.Threading.Tasks;
    namespace BlazorTranslator.Data
    {
        
        public class TranslationService
        {
            private static readonly string location = &quot;eastus&quot;;
            
            public async Task&lt;TranslationResult[]&gt; GetTranslatation(string textToTranslate, string targetLanguage)
            {
                string subscriptionKey = &quot;52937b775b454b65830ac59e5dc22d9d&quot;;
                string apiEndpoint = &quot;https://api.cognitive.microsofttranslator.com/&quot;;
                string route = $&quot;/translate?api-version=3.0&amp;to={targetLanguage}&quot;;
                string requestUri = apiEndpoint + route;
                TranslationResult[] translationResult = await TranslateText(subscriptionKey, requestUri, textToTranslate);
                return translationResult;
            }
            async Task&lt;TranslationResult[]&gt; TranslateText(string subscriptionKey, string requestUri, string inputText)
            {
                object[] body = new object[] { new { Text = inputText } };
                var requestBody = JsonConvert.SerializeObject(body);
                using (var client = new HttpClient())
                using (var request = new HttpRequestMessage())
                {
                    request.Method = HttpMethod.Post;
                    request.RequestUri = new Uri(requestUri);
                    request.Content = new StringContent(requestBody, Encoding.UTF8, &quot;application/json&quot;);
                    request.Headers.Add(&quot;Ocp-Apim-Subscription-Key&quot;, subscriptionKey);
                    request.Headers.Add(&quot;Ocp-Apim-Subscription-Region&quot;, location);
                    HttpResponseMessage response = await client.SendAsync(request).ConfigureAwait(false);
                    string result = await response.Content.ReadAsStringAsync();
                    TranslationResult[] deserializedOutput = JsonConvert.DeserializeObject&lt;TranslationResult[]&gt;(result);
                    return deserializedOutput;
                }
            }
            public async Task&lt;AvailableLanguage&gt; GetAvailableLanguages()
            {
                string endpoint = &quot;https://api.cognitive.microsofttranslator.com/languages?api-version=3.0&amp;scope=translation&quot;;
                var client = new HttpClient();
                using (var request = new HttpRequestMessage())
                {
                    request.Method = HttpMethod.Get;
                    request.RequestUri = new Uri(endpoint);
                    var response = await client.SendAsync(request).ConfigureAwait(false);
                    string result = await response.Content.ReadAsStringAsync();
                    AvailableLanguage deserializedOutput = JsonConvert.DeserializeObject&lt;AvailableLanguage&gt;(result);
                    return deserializedOutput;
                }
            }
        }
    }

```

We have defined a &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;GetTranslatation&lt;/span&gt; method which will accept two parameters – the text to translate and the target language. We will set the subscription key for the Azure Translator Text cognitive service and define a variable for the global endpoint for Translator Text. The request URL contains the API endpoint along with the target language.

Inside the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;TranslateText&lt;/span&gt; method, we will create a new &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;HttpRequestMessage&lt;/span&gt;. This HTTP request is a Post request. We will pass the subscription key in the header of the request. The Translator Text API returns a JSON object, which will be deserialized to an array of type &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;TranslationResult&lt;/span&gt;. The output contains the translated text as well as the language detected for the input text.

The &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;GetAvailableLanguages&lt;/span&gt; method will return the list of all the language supported by the Translate Text API. We will set the request URI and create a &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;HttpRequestMessage&lt;/span&gt; which will be a Get request. This request URL will return a JSON object which will be deserialized to an object of type &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;AvailableLanguage&lt;/span&gt;.

## Configuring the Service

To make the service available to the components we need to configure it on the server-side app. Open the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;Startup.cs file&lt;/span&gt;. Add the following line inside the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;ConfigureServices&lt;/span&gt; method of Startup class.

```code

    services.AddSingleton&lt;TranslationService&gt;();

```

## Creating the Blazor UI Component

We will add the Razor page in the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;BlazorTranslator/Pages&lt;/span&gt; folder. By default, we have “Counter” and “Fetch Data” pages provided in our application. These default pages will not affect our application but for the sake of this tutorial, we will delete fetchdata and counter pages from &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;BlazorTranslator/Pages&lt;/span&gt; folder.

Right-click on the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;BlazorTranslator/Pages folder&lt;/span&gt; and then select Add &gt;&gt; New Item. An “Add New Item” dialog box will open, select “Visual C#” from the left panel, then select “Razor Component” from the templates panel, put the name as &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;Translator.razor&lt;/span&gt;. Click Add. Refer to the image shown below.

![image info](/img/azure/11/AddBlazorComponet.png)

We will add a code-behind file for this razor page to keep the code and presentation separate. This will allow easy maintenance for the application.  Right-click on the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;BlazorComputerVision/Pages&lt;/span&gt; folder and then select Add &gt;&gt; Class. Name the class as &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;OCR.razor.cs&lt;/span&gt;. The Blazor framework is smart enough to tag this class file to the razor file. Refer to the image shown below.

![image info](/img/azure/10/OCRStuct.png)

Open the Translator.razor file and add the following code at the top.

```code

    @page &quot;/translator&quot;
    @using BlazorTranslator.Models
    @using BlazorTranslator.Data
    @inject TranslationService translationService

```

We have defined the route for this component. We are also injecting the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;TranslationService&lt;/span&gt; in this component.

Now we will add the following HTML code in this file.

```code

    &lt;h3&gt;Multilanguage translator using Microsoft Translator API Cognitive Service&lt;/h3&gt;
&lt;hr /&gt;
&lt;div class=&quot;container&quot;&gt;
    &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-md-6&quot;&gt;
            &lt;select class=&quot;form-control&quot; @bind=&quot;inputLanguage&quot;&gt;
                &lt;option value=&quot;&quot;&gt;-- Select input language --&lt;/option&gt;
                @foreach (KeyValuePair&lt;string, LanguageDetails&gt; lang in LanguageList)
                {
                    &lt;option value=&quot;@lang.Key&quot;&gt;@lang.Value.Name&lt;/option&gt;
                }
            &lt;/select&gt;
            &lt;textarea placeholder=&quot;Enter text to translate&quot; class=&quot;form-control translation-box&quot; rows=&quot;5&quot; @bind=&quot;@inputText&quot;&gt;&lt;/textarea&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-md-6&quot;&gt;
            &lt;select class=&quot;form-control&quot; @onchange=&quot;SelectLanguage&quot;&gt;
                &lt;option value=&quot;&quot;&gt;-- Select target language --&lt;/option&gt;
                @foreach (KeyValuePair&lt;string, LanguageDetails&gt; lang in LanguageList)
                {
                    &lt;option value=&quot;@lang.Key&quot;&gt;@lang.Value.Name&lt;/option&gt;
                }
            &lt;/select&gt;
            &lt;textarea disabled class=&quot;form-control translation-box&quot; rows=&quot;5&quot;&gt;@outputText&lt;/textarea&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&quot;text-center&quot;&gt;
        &lt;button class=&quot;btn btn-primary btn-lg&quot; @onclick=&quot;Translate&quot;&gt;Translate&lt;/button&gt;
    &lt;/div&gt;
&lt;/div&gt;
```
We have defined two dropdown lists one each for input language and the target language. The Azure Translate Text API will detect the input language and we will use that value to populate the dropdown for input language. We have also defined two text areas for the input and the translated text.

Finally, add the following code in the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;@code &lt;/span&gt; section of the page.

```code
    @code {
        private TranslationResult[] translations;
        private AvailableLanguage availableLanguages;
        private string outputLanguage { get; set; }
        private string inputLanguage { get; set; }
        string inputText { get; set; }
        string outputText { get; set; }
        private Dictionary&lt;string, LanguageDetails&gt;
        LanguageList = new Dictionary&lt;string, LanguageDetails&gt;();

        protected override async Task OnInitializedAsync()
        {
            availableLanguages = await translationService.GetAvailableLanguages();
            LanguageList = availableLanguages.Translation;
        }
        private void SelectLanguage(ChangeEventArgs langEvent)
        {
            this.outputLanguage = langEvent.Value.ToString();
        }
        private async Task Translate()
        {
            if (!string.IsNullOrEmpty(outputLanguage))
            {
                translations = await translationService.GetTranslatation(this.inputText, this.outputLanguage);
                outputText = translations[0].Translations[0].Text;
                inputLanguage = translations[0].DetectedLanguage.Language;
            }
        }
    }
```

We are invoking the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;GetAvailableLanguages&lt;/span&gt; method from our service inside the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;OnInitializedAsync&lt;/span&gt;. This &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;OnInitializedAsync&lt;/span&gt; is a lifecycle method that will be invoked upon component initialization. This will make sure that the language dropdown will be populated as the page loads.

The &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;SelectLanguage&lt;/span&gt; method will be set the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;outputLanguage&lt;/span&gt; for the translation. The Translate method will invoke the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;GetTranslatation&lt;/span&gt; method from the service. We will set the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;outputText&lt;/span&gt; and the language detected for the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;inputLanguage&lt;/span&gt; as returned from the service.

## Add styling for the Translator component
Navigate to BlazorTranslator\wwwroot\css\site.css file and put the following style definition inside it.

```code

    .translation-box {
        margin: 15px 0px;
    }
```

## Adding Link to Navigation menu
The last step is to add the link of our Translator component in the navigation menu. Open BlazorTranslator/Shared/NavMenu.razor file and add the following code into it.

```code 

    &lt;li class=&quot;nav-item px-3&quot;&gt;
    &lt;NavLink class=&quot;nav-link&quot; href=&quot;translator&quot;&gt;
        &lt;span class=&quot;oi oi-list-rich&quot; aria-hidden=&quot;true&quot;&gt;&lt;/span&gt; Translator
    &lt;/NavLink&gt;
    &lt;/li&gt;
```
Remove the navigation links for Counter and Fetch-data components as they are not required for this application.

## Execution Demo

Press F5 to launch the application. Click on the Translator button on the nav menu in the left. You can perform the multilanguage translation as shown in the image below.

![image info](/img/azure/11/output.gif)

## Summary

We have created a Translator Text Cognitive Services resource on Azure. We have used the Translator Text API to create a multilanguage translator using Blazor. This translator supports more than 60 languages for translation. We fetched the list of supported languages for translation from the global API endpoint for Translator Text.

Get the Source code from [GitHub](https://github.com/girishgodage/Blazor-Translator-Azure-Cognitive-Services) and play around to get a better understanding.</content><author><name>Girish Godage</name></author><category term="learning" /><summary type="html">Introduction</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/img/azure/11/output.gif" /></entry><entry><title type="html">Optical Character Reader Using Angular And Azure Computer Vision</title><link href="http://localhost:4000/blog/ocr-using-angular-AzureComputerVision" rel="alternate" type="text/html" title="Optical Character Reader Using Angular And Azure Computer Vision" /><published>2020-12-17T09:55:00+00:00</published><updated>2020-12-17T09:55:00+00:00</updated><id>http://localhost:4000/blog/ocr-using-angular-AzureComputerVision</id><content type="html" xml:base="http://localhost:4000/blog/ocr-using-angular-AzureComputerVision">## Introduction

In this article, we will create an optical character recognition (OCR) application using Angular and the Azure Computer Vision Cognitive Service. Computer Vision is an AI service that analyzes content in images. We will use the OCR feature of Computer Vision to detect the printed text in an image. The application will extract the text from the image and detects the language of the text. Currently, the OCR API supports 25 languages.

## Prerequisites

  * Install the latest LTS version of Node.JS from https://nodejs.org/en/download/
  * Install the Angular CLI from https://cli.angular.io/
  * An Azure subscription account. You can create a free  Azure account at https://azure.microsoft.com/en-in/free/
  * Install the .NET Core 3.1 SDK from https://dotnet.microsoft.com/download/dotnet-core/3.1
  * Install the latest version of Visual Studio 2019 from https://visualstudio.microsoft.com/downloads/


&gt; We will use an &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;ASP.NET Core backend &lt;/span&gt; for this application. The &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt; ASP.NET Core backend &lt;/span&gt; provides a straight forward authentication process to access Azure cognitive services. This will also ensure that the end-user won’t have direct access to cognitive services.

## Create the Azure Computer Vision Cognitive Service resource

Log in to the Azure portal and search for the cognitive services in the search bar and click on the result. Refer to the image shown below.

![image info](/img/azure/9/SearchCognitive.png)

On the next screen, click on the Add button. It will open the cognitive services marketplace page. Search for the Computer Vision in the search bar and click on the search result. It will open the Computer Vision API page. Click on the Create button to create a new Computer Vision resource. Refer to the image shown below.

![image info](/img/azure/9/CreateComputerVision.png)

On the Create page, fill in the details as indicated below.

  * **Name**: Give a unique name for your resource.
  * **Subscription**: Select the subscription type from the dropdown.
  * **Pricing tier**: Select the pricing tier as per your choice.
  * **Resource group**: Select an existing resource group or create a new one.

Click on the Create button. Refer to the image shown below.

![image info](/img/azure/9/CreateComputerVision_1.png)

![image info](/img/azure/9/CreateComputerVision_2.png)


After your resource is successfully deployed, click on the “Go to resource” button. You can see the Key and the endpoint for the newly created Computer Vision resource. Refer to the image shown below.

![image info](/img/azure/9/ComputerVisionKeyNEndPoint.png)


Make a note of the **key and the endpoint**. We will be using these in the latter part of this article to invoke the Computer Vision OCR API from the .NET Code. The values are masked here for privacy.

## Creating the ASP.NET Core application

Open Visual Studio 2019 and click on “Create a new Project”. A “Create a new Project” dialog will open. Select “ASP.NET Core Web Application” and click on Next. Now you will be at “Configure your new project” screen, provide the name for your application as ngComputerVision and click on create. Refer to the image shown below.

![image info](/img/azure/9/Configure_CoreWebApp.png)

You will be navigated to “Create a new ASP.NET Core web application” screen. Select “.NET Core” and “ASP.NET Core 3.1” from the dropdowns on the top. Then, select the “Angular” project template and click on Create. Refer to the image shown below.

![image info](/img/azure/9/Create_CoreWebApp.png)

This will create our project. The folder structure of the application is shown below.

![image info](/img/azure/9/SolutionFolderStructure.png)

The &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;ClientApp &lt;/span&gt; folder contains the Angular code for our application. The Controllers folders will contain our API controllers. The angular components are present inside the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;ClientApp\src\app &lt;/span&gt; folder. The default template contains few Angular components. These components won’t affect our application, but for the sake of simplicity, we will delete fetchdata and counter folders from &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;ClientApp/app/components&lt;/span&gt; folder. Also, remove the reference for these two components from the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;app.module.ts&lt;/span&gt; file.


## Installing Computer Vision API library
We will install the Azure Computer Vision API library which will provide us with the models out of the box to handle the Computer Vision REST API response. To install the package, navigate to Tools &gt;&gt; NuGet Package Manager &gt;&gt; Package Manager Console. It will open the Package Manager Console. Run the command as shown below.

```code
  Install-Package Microsoft.Azure.CognitiveServices.Vision.ComputerVision -Version 5.0.0

```
You can learn more about this package at the [NuGet gallery](https://www.nuget.org/packages/Microsoft.Azure.CognitiveServices.Vision.ComputerVision/).

## Create the Models

Right-click on the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;ngComputerVision&lt;/span&gt; project and select Add &gt;&gt; New Folder. Name the folder as Models. Again, right-click on the Models folder and select Add &gt;&gt; Class to add a new class file. Put the name of your class as &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;LanguageDetails.cs&lt;/span&gt; and click Add.

Open &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;LanguageDetails.cs&lt;/span&gt; and put the following code inside it.

```code
  namespace ngComputerVision.Models
{
    public class LanguageDetails
    {
        public string Name { get; set; }
        public string NativeName { get; set; }
        public string Dir { get; set; }
    }
}

```

Similarly, add a new class file &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;AvailableLanguage.cs &lt;/span&gt; and put the following code inside it.

```code
  using System.Collections.Generic;
  namespace ngComputerVision.Models
  {
      public class AvailableLanguage
      {
          public Dictionary&lt;string, LanguageDetails&gt; Translation { get; set; }
      }
  }

```
We will also add two classes as DTO (Data Transfer Object) for sending data back to the client.

Create a new folder and name it &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;DTOModels&lt;/span&gt;. Add the new class file &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;AvailableLanguageDTO.cs&lt;/span&gt; in the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;DTOModels&lt;/span&gt; folder and put the following code inside it.

```code

  namespace ngComputerVision.DTOModels
  {
      public class AvailableLanguageDTO
      {
          public string LanguageID { get; set; }
          public string LanguageName { get; set; }
      }
  }

```

Add the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;OcrResultDTO.cs&lt;/span&gt; file and put the following code inside it.

```code
  namespace ngComputerVision.DTOModels
  {
      public class OcrResultDTO
      {
          public string Language { get; set; }
          public string DetectedText { get; set; }
      }
  }

```
## Adding the OCR Controller

We will add a new controller to our application. Right-click on the Controllers folder and select Add &gt;&gt; New Item. An “Add New Item” dialog box will open. Select “Visual C#” from the left panel, then select “API Controller Class” from templates panel and put the name as &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;OCRController.cs&lt;/span&gt;. Click on Add. Refer to the image below.

![image info](/img/azure/9/AddAPIController.png)

The OCRController will handle the image recognition requests from the client app. This controller will also return the list of all the languages supported by OCR API.

Open the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;OCRController.cs&lt;/span&gt; file and put the following code inside it.

```code
  using System;
  using System.Threading.Tasks;
  using Microsoft.AspNetCore.Mvc;
  using System.Net.Http;
  using System.Net.Http.Headers;
  using Newtonsoft.Json.Linq;
  using System.IO;
  using Newtonsoft.Json;
  using System.Text;
  using ngComputerVision.Models;
  using System.Collections.Generic;
  using Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models;
  using ngComputerVision.DTOModels;
  namespace ngComputerVision.Controllers
  {
      [Produces(&quot;application/json&quot;)]
      [Route(&quot;api/[controller]&quot;)]
      public class OCRController : Controller
      {
          static string subscriptionKey;
          static string endpoint;
          static string uriBase;
          public OCRController()
          {
              subscriptionKey = &quot;fc791774e60e455da79546c50e1ca504&quot;;
              endpoint = &quot;https://ngocrdemo.cognitiveservices.azure.com/&quot;;
              uriBase = endpoint + &quot;vision/v2.1/ocr&quot;;
          }
          [HttpPost, DisableRequestSizeLimit]
          public async Task&lt;OcrResultDTO&gt; Post()
          {
              StringBuilder sb = new StringBuilder();
              OcrResultDTO ocrResultDTO = new OcrResultDTO();
              try
              {
                  if (Request.Form.Files.Count &gt; 0)
                  {
                      var file = Request.Form.Files[Request.Form.Files.Count - 1];
                      if (file.Length &gt; 0)
                      {
                          var memoryStream = new MemoryStream();
                          file.CopyTo(memoryStream);
                          byte[] imageFileBytes = memoryStream.ToArray();
                          memoryStream.Flush();
                          string JSONResult = await ReadTextFromStream(imageFileBytes);
                          OcrResult ocrResult = JsonConvert.DeserializeObject&lt;OcrResult&gt;(JSONResult);
                          if (!ocrResult.Language.Equals(&quot;unk&quot;))
                          {
                              foreach (OcrLine ocrLine in ocrResult.Regions[0].Lines)
                              {
                                  foreach (OcrWord ocrWord in ocrLine.Words)
                                  {
                                      sb.Append(ocrWord.Text);
                                      sb.Append(' ');
                                  }
                                  sb.AppendLine();
                              }
                          }
                          else
                          {
                              sb.Append(&quot;This language is not supported.&quot;);
                          }
                          ocrResultDTO.DetectedText = sb.ToString();
                          ocrResultDTO.Language = ocrResult.Language;
                      }
                  }
                  return ocrResultDTO;
              }
              catch
              {
                  ocrResultDTO.DetectedText = &quot;Error occurred. Try again&quot;;
                  ocrResultDTO.Language = &quot;unk&quot;;
                  return ocrResultDTO;
              }
          }
          static async Task&lt;string&gt; ReadTextFromStream(byte[] byteData)
          {
              try
              {
                  HttpClient client = new HttpClient();
                  client.DefaultRequestHeaders.Add(&quot;Ocp-Apim-Subscription-Key&quot;, subscriptionKey);
                  string requestParameters = &quot;language=unk&amp;detectOrientation=true&quot;;
                  string uri = uriBase + &quot;?&quot; + requestParameters;
                  HttpResponseMessage response;
                  using (ByteArrayContent content = new ByteArrayContent(byteData))
                  {
                      content.Headers.ContentType = new MediaTypeHeaderValue(&quot;application/octet-stream&quot;);
                      response = await client.PostAsync(uri, content);
                  }
                  string contentString = await response.Content.ReadAsStringAsync();
                  string result = JToken.Parse(contentString).ToString();
                  return result;
              }
              catch (Exception e)
              {
                  return e.Message;
              }
          }
          [HttpGet]
          public async Task&lt;List&lt;AvailableLanguageDTO&gt;&gt; GetAvailableLanguages()
          {
              string endpoint = &quot;https://api.cognitive.microsofttranslator.com/languages?api-version=3.0&amp;scope=translation&quot;;
              var client = new HttpClient();
              using (var request = new HttpRequestMessage())
              {
                  request.Method = HttpMethod.Get;
                  request.RequestUri = new Uri(endpoint);
                  var response = await client.SendAsync(request).ConfigureAwait(false);
                  string result = await response.Content.ReadAsStringAsync();
                  AvailableLanguage deserializedOutput = JsonConvert.DeserializeObject&lt;AvailableLanguage&gt;(result);
                  List&lt;AvailableLanguageDTO&gt; availableLanguage = new List&lt;AvailableLanguageDTO&gt;();
                  foreach (KeyValuePair&lt;string, LanguageDetails&gt; translation in deserializedOutput.Translation)
                  {
                      AvailableLanguageDTO language = new AvailableLanguageDTO();
                      language.LanguageID = translation.Key;
                      language.LanguageName = translation.Value.Name;
                      availableLanguage.Add(language);
                  }
                  return availableLanguage;
              }
          }
      }
  } 

```

In the constructor of the class, we have initialized the key and the endpoint URL for the OCR API.

The Post method will receive the image data as a file collection in the request body and return an object of type &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;OcrResultDTO&lt;/span&gt;. We will convert the image data to a byte array and invoke the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;ReadTextFromStream&lt;/span&gt; method. We will deserialize the response into an object of type &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;OcrResult&lt;/span&gt;. We will then form the sentence by iterating over the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;OcrWord&lt;/span&gt; object.

Inside the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;ReadTextFromStream&lt;/span&gt; method, we will create a new &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;HttpRequestMessage&lt;/span&gt;. This HTTP request is a Post request. We will pass the subscription key in the header of the request. The OCR API will return a JSON object having each word from the image as well as the detected language of the text.

The &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;GetAvailableLanguages&lt;/span&gt; method will return the list of all the language supported by the Translate Text API. We will set the request URI and create a &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;HttpRequestMessage&lt;/span&gt; which will be a Get request. This request URI will return a JSON object which will be deserialized to an object of type &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;AvailableLanguage&lt;/span&gt;.

## Why do we need to fetch the list of supported languages?

The OCR API returns the language code (e.g. en for English, de for German, etc.) of the detected language. But we cannot display the language code on the UI as it is not user-friendly. Therefore, we need a dictionary to look up the language name corresponding to the language code.

The Azure Computer Vision OCR API supports 25 languages. To know all the languages supported by OCR API see the list of [supported languages](https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/language-support). These languages are a subset of the languages supported by the Azure Translate Text API. Since there is no dedicated API endpoint to fetch the list of languages supported by OCR API, therefore, we are using the Translate Text API endpoint to fetch the list of languages. We will create the language lookup dictionary using the JSON response from this API call and filter the result based on the language code returned by the OCR API.

## Working on the Client side of the application

The code for the client-side is available in the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;ClientApp&lt;/span&gt; folder. We will use Angular CLI to work with the client code.

&gt; Using Angular CLI is not mandatory. I am using Angular CLI here as it is user-friendly and easy to use. If you don’t want to use CLI then you can create the files for components and services manually.

Navigate to the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;ngComputerVision\ClientApp &lt;/span&gt; folder in your machine and open a command window. We will execute all our Angular CLI commands in this window.

## Create the models

Create a folder called &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;models&lt;/span&gt; inside the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;ClientApp\src\app&lt;/span&gt; folder. Now we will create a file &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;availablelanguage.ts&lt;/span&gt; in the models folder. Put the following code in it.

```code
  export class AvailableLanguage {
    languageID: string;
    languageName: string;
  }

```

Similarly, create another file inside the models folder called &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;ocrresult.ts&lt;/span&gt;. Put the following code in it.

```code
  export class OcrResult {
    language: string;
    detectedText: string
  }

```

You can observe that both these classes have the same definition as the DTO classes we created on the server-side. This will allow us to bind the data returned from the server directly to our models.

## Create the Computer Vision Service

We will create an Angular service which will invoke the Web API endpoints, convert the Web API response to JSON and pass it to our component. Run the following command.

```code

  ng g s services\Computervision

```

This command will create a folder name as services and then create the following two files inside it.

  * **computervision.service.ts** — the service class file.
  * **computervision.service.spec.ts** — the unit test file for service.
  
Open &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;computervision.service.ts&lt;/span&gt; file and put the following code inside it.

```code
  import { Injectable } from '@angular/core';
  import { HttpClient } from '@angular/common/http';
  @Injectable({
    providedIn: 'root'
  })
  export class ComputervisionService {
    baseURL: string;
    constructor(private http: HttpClient) {
      this.baseURL = '/api/OCR';
    }
    getAvailableLanguage() {
      return this.http.get(this.baseURL)
        .pipe(response =&gt; {
          return response;
        });
    }
    getTextFromImage(image: FormData) {
      return this.http.post(this.baseURL, image)
        .pipe(response =&gt; {
          return response;
        });
    }
  }

```
We have defined a variable baseURL which will hold the endpoint URL of our API. We will initialize the baseURL in the constructor and set it to the endpoint of the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;OCRController&lt;/span&gt;.

The &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;getAvailableLanguage&lt;/span&gt; method will send a Get request to the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;GetAvailableLanguages&lt;/span&gt; method of the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;OCRController&lt;/span&gt; to fetch the list of supported languages for OCR.

The &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;getTextFromImage&lt;/span&gt; method will send a Post request to the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;OCRController&lt;/span&gt; and supply the parameter of type &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;FormData&lt;/span&gt;. It will fetch the detected text from the image and language code of the text.

## Create the Ocr component

Run the following command in the command prompt to create the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;OcrComponent&lt;/span&gt;.

```code
  
  ng g c ocr --module app

```

The --module flag will ensure that this component will get registered at &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;app.module.ts&lt;/span&gt;.

Open &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;ocr.component.html&lt;/span&gt; and put the following code in it.

```code
    &lt;h2&gt;Optical Character Recognition (OCR) using Angular and Azure Computer Vision Cognitive Services&lt;/h2&gt;
  &lt;div class=&quot;row&quot;&gt;
    &lt;div class=&quot;col-md-5&quot;&gt;
      &lt;textarea disabled class=&quot;form-control&quot; rows=&quot;10&quot; cols=&quot;15&quot;&gt;{{ocrResult?.detectedText}}&lt;/textarea&gt;
      &lt;hr /&gt;
      &lt;div class=&quot;row&quot;&gt;
        &lt;div class=&quot;col-sm-5&quot;&gt;
          &lt;label&gt;&lt;strong&gt; Detected Language :&lt;/strong&gt;&lt;/label&gt;
        &lt;/div&gt;
        &lt;div class=&quot;col-sm-6&quot;&gt;
          &lt;input disabled type=&quot;text&quot; class=&quot;form-control&quot; value={{DetectedTextLanguage}} /&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&quot;col-md-5&quot;&gt;
      &lt;div class=&quot;image-container&quot;&gt;
        &lt;img class=&quot;preview-image&quot; src={{imagePreview}}&gt;
      &lt;/div&gt;
      &lt;input type=&quot;file&quot; (change)=&quot;uploadImage($event)&quot; /&gt;
      &lt;p&gt;{{status}}&lt;/p&gt;
      &lt;hr /&gt;
      &lt;button [disabled]=&quot;loading&quot; class=&quot;btn btn-primary btn-lg&quot; (click)=&quot;GetText()&quot;&gt;
        &lt;span *ngIf=&quot;loading&quot; class=&quot;spinner-border spinner-border-sm mr-1&quot;&gt;&lt;/span&gt;Extract Text
      &lt;/button&gt;
    &lt;/div&gt;
  &lt;/div&gt;
```

We have defined a text area to display the detected text and a text box for displaying the detected language. We have defined a file upload control which will allow us to upload an image. After uploading the image, the preview of the image will be displayed using an &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;img&lt;/span&gt; element.

Open &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;ocr.component.ts&lt;/span&gt; and put the following code in it.

```code
  import { Component, OnInit } from '@angular/core';
import { ComputervisionService } from '../services/computervision.service';
import { AvailableLanguage } from '../models/availablelanguage';
import { OcrResult } from '../models/ocrresult';
@Component({
  selector: 'app-ocr',
  templateUrl: './ocr.component.html',
  styleUrls: ['./ocr.component.css']
})
export class OcrComponent implements OnInit {
  loading = false;
  imageFile;
  imagePreview;
  imageData = new FormData();
  availableLanguage: AvailableLanguage[];
  DetectedTextLanguage: string;
  ocrResult: OcrResult;
  DefaultStatus: string;
  status: string;
  maxFileSize: number;
  isValidFile = true;
  constructor(private computervisionService: ComputervisionService) {
    this.DefaultStatus = &quot;Maximum size allowed for the image is 4 MB&quot;;
    this.status = this.DefaultStatus;
    this.maxFileSize = 4 * 1024 * 1024; // 4MB
  }
  ngOnInit() {
    this.computervisionService.getAvailableLanguage().subscribe(
      (result: AvailableLanguage[]) =&gt; this.availableLanguage = result
    );
  }
  uploadImage(event) {
    this.imageFile = event.target.files[0];
    if (this.imageFile.size &gt; this.maxFileSize) {
      this.status = `The file size is ${this.imageFile.size} bytes, this is more than the allowed limit of ${this.maxFileSize} bytes.`;
      this.isValidFile = false;
    } else if (this.imageFile.type.indexOf('image') == -1) {
      this.status = &quot;Please upload a valid image file&quot;;
      this.isValidFile = false;
    } else {
      const reader = new FileReader();
      reader.readAsDataURL(event.target.files[0]);
      reader.onload = () =&gt; {
        this.imagePreview = reader.result;
      };
      this.status = this.DefaultStatus;
      this.isValidFile = true;
    }
  }
  GetText() {
    if (this.isValidFile) {
      this.loading = true;
      this.imageData.append('imageFile', this.imageFile);
      this.computervisionService.getTextFromImage(this.imageData).subscribe(
        (result: OcrResult) =&gt; {
          this.ocrResult = result;
          if (this.availableLanguage.find(x =&gt; x.languageID === this.ocrResult.language)) {
            this.DetectedTextLanguage = this.availableLanguage.find(x =&gt; x.languageID === this.ocrResult.language).languageName;
          } else {
            this.DetectedTextLanguage = &quot;unknown&quot;;
          }
          this.loading = false;
        });
    }
  }
}
```

We will inject the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;ComputervisionService&lt;/span&gt; in the constructor of the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;OcrComponent&lt;/span&gt; and set a message and the value for the max image size allowed inside the constructor.

We will invoke the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;getAvailableLanguage&lt;/span&gt; method of our service in the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;ngOnInit&lt;/span&gt; and store the result in an array of type &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;AvailableLanguage&lt;span&gt;.

The &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;uploadImage&lt;/span&gt; method will be invoked upon uploading an image. We will check if the uploaded file is a valid image and within the allowed size limit. We will process the image data using a &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;FileReader&lt;/span&gt; object. The &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;readAsDataURL&lt;/span&gt; method will read the contents of the uploaded file. Upon successful completion of the read operation, the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;reader.onload&lt;/span&gt; event will be triggered. The value of &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;imagePreview&lt;/span&gt; will be set to the result returned by the fileReader object, which is of type &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;ArrayBuffer&lt;/span&gt;.

Inside the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;GetText&lt;/span&gt; method, we will append the image file to a variable for type &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;FormData&lt;/span&gt;. We will invoke the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;getTextFromImage&lt;/span&gt; of the service and bind the result to an object of type &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;OcrResult&lt;/span&gt;. We will search for the language name from the array &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;availableLanguage&lt;/span&gt;, based on the language code returned from the service. If the language code is not found, we will set the language as unknown.

We will add the styling for the text area in &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;ocr.component.css&lt;/span&gt; as shown below.

```code

  .preview-image {
      max-height: 300px;
      max-width: 300px;
  }
  .image-container{
    display: flex;
    padding: 15px;
    align-content: center;
    align-items: center;
    justify-content: center;
    border: 2px dashed skyblue;
  }

```

## Adding the links in Nav Menu

We will add the navigation links for our components in the nav menu. Open &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;nav-menu.component.html&lt;/span&gt; and remove the links for Counter and Fetch data components. Add the following lines in the list of navigation links.

```code
  &lt;li class=&quot;nav-item&quot; [routerLinkActive]=&quot;['link-active']&quot;&gt;
    &lt;a class=&quot;nav-link text-dark&quot; routerLink='/computer-vision-ocr'&gt;Computer Vision&lt;/a&gt;
  &lt;/li&gt;
```

## Execution Demo

Press F5 to launch the application. Click on the Computer Vision button on the nav menu at the top. You can upload an image and extract the text from the image as shown in the image below.

![image info](/img/azure/9/output.gif)


## Summary

We have created an optical character recognition (OCR) application using Angular and the Computer Vision Azure Cognitive Service. The application is able to extract the printed text from the uploaded image and recognizes the language of the text. The OCR API of the Computer Vision is used which can recognize text in 25 languages.

Get the Source code from [GitHub](https://github.com/girishgodage/AngularComputerVisionAzureCognitiveServices) and play around to get a better understanding.</content><author><name>Girish Godage</name></author><category term="learning" /><summary type="html">Introduction</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/img/azure/9/output.gif" /></entry><entry><title type="html">Optical Character Reader Using Blazor And Azure Computer Vision</title><link href="http://localhost:4000/blog/ocr-using-blazor-AzureComputerVision" rel="alternate" type="text/html" title="Optical Character Reader Using Blazor And Azure Computer Vision" /><published>2020-12-17T09:55:00+00:00</published><updated>2020-12-17T09:55:00+00:00</updated><id>http://localhost:4000/blog/ocr-using-blazor-AzureComputerVision</id><content type="html" xml:base="http://localhost:4000/blog/ocr-using-blazor-AzureComputerVision">## Introduction

In this article, we will create an optical character recognition (OCR) application using Blazor and the Azure Computer Vision Cognitive Service. Computer Vision is an AI service that analyzes content in images. We will use the OCR feature of Computer Vision to detect the printed text in an image. The application will extract the text from the image and detects the language of the text. Currently, the OCR API supports 25 languages.

![image info](/img/azure/10/output.gif)

## Prerequisites
  * Install the latest .NET Core 3.1 SDK from https://dotnet.microsoft.com/download/dotnet-core/3.1
  * Install the latest version of Visual Studio 2019 from https://visualstudio.microsoft.com/downloads/
 * An Azure subscription account. You can create a free Azure account  at https://azure.microsoft.com/en-in/free/

## Image requirements

The OCR API will work on images that meet the requirements as mentioned below:

  * The format of the image must be JPEG, PNG, GIF, or BMP.
  * The size of the image must be between 50 x 50 and 4200 x 4200 pixels.
  * The image file size should be less than 4 MB.
  * The text in the image can be rotated by any multiple of 90 degrees plus a small angle of up to 40 degrees.

## Create the Azure Computer Vision Cognitive Service resource

Log in to the Azure portal and search for the cognitive services in the search bar and click on the result. Refer to the image shown below.

![image info](/img/azure/9/SearchCognitive.png)

On the next screen, click on the Add button. It will open the cognitive services marketplace page. Search for the Computer Vision in the search bar and click on the search result. It will open the Computer Vision API page. Click on the Create button to create a new Computer Vision resource. Refer to the image shown below.

![image info](/img/azure/9/CreateComputerVision.png)

On the Create page, fill in the details as indicated below.

  * **Name**: Give a unique name for your resource.
  * **Subscription**: Select the subscription type from the dropdown.
  * **Pricing tier**: Select the pricing tier as per your choice.
  * **Resource group**: Select an existing resource group or create a new one.

Click on the Create button. Refer to the image shown below.

![image info](/img/azure/10/CreateComputerVision.png)

![image info](/img/azure/10/CreateComputerVision_1.png)


After your resource is successfully deployed, click on the “Go to resource” button. You can see the Key and the endpoint for the newly created Computer Vision resource. Refer to the image shown below.

![image info](/img/azure/10/ComputerVisionKeyNEndPoint.png)


Make a note of the **key and the endpoint**. We will be using these in the latter part of this article to invoke the Computer Vision OCR API from the .NET Code. The values are masked here for privacy.

## Create a Server-Side Blazor Application

Open Visual Studio 2019, click on “Create a new project”. Select “Blazor App” and click on the “Next” button. Refer to the image shown below.

![image info](/img/azure/10/Create_BlazorApp.png)

On the next window, put the project name as &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;BlazorComputerVision&lt;/span&gt; and click on the “Create” button. The next window will ask you to select the type of Blazor app. Select &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;Blazor Server App &lt;/span&gt; and click on the Create button to create a new server-side Blazor application. Refer to the image shown below.

![image info](/img/azure/10/Create_BlazorApp_1.png)

## Installing Computer Vision API library
We will install the Azure Computer Vision API library which will provide us with the models out of the box to handle the Computer Vision REST API response. To install the package, navigate to Tools &gt;&gt; NuGet Package Manager &gt;&gt; Package Manager Console. It will open the Package Manager Console. Run the command as shown below.

```code
  Install-Package Microsoft.Azure.CognitiveServices.Vision.ComputerVision -Version 5.0.0

```
You can learn more about this package at the [NuGet gallery](https://www.nuget.org/packages/Microsoft.Azure.CognitiveServices.Vision.ComputerVision/).

## Create the Models

Right-click on the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;BlazorComputerVision&lt;/span&gt; project and select Add &gt;&gt; New Folder. Name the folder as Models. Again, right-click on the Models folder and select Add &gt;&gt; Class to add a new class file. Put the name of your class as &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;LanguageDetails.cs&lt;/span&gt; and click Add.

Open &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;LanguageDetails.cs&lt;/span&gt; and put the following code inside it.

```code
  namespace BlazorComputerVision.Models
  {
      public class LanguageDetails
      {
          public string Name { get; set; }
          public string NativeName { get; set; }
          public string Dir { get; set; }
      }
  }

```

Similarly, add a new class file &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;AvailableLanguage.cs &lt;/span&gt; and put the following code inside it.

```code
 using System.Collections.Generic;
  namespace BlazorComputerVision.Models
  {
      public class AvailableLanguage
      {
          public Dictionary&lt;string, LanguageDetails&gt; Translation { get; set; }
      }
  }

```
Finally, we will add a class as DTO (Data Transfer Object) for sending data back to the client.Add the new class file &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;OcrResultDTO.cs&lt;/span&gt; in the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;Models&lt;/span&gt; folder and put the following code inside it.

```code

  namespace BlazorComputerVision.Models
  {
      public class OcrResultDTO
      {
          public string Language { get; set; }
          public string DetectedText { get; set; }
      }
  }

```

## Create the Computer Vision Service

Right-click on the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;BlazorComputerVision/Data&lt;/span&gt; folder and select Add &gt;&gt; Class to add a new class file. Put the name of the file as &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;ComputerVisionService.cs&lt;/span&gt; and click on Add.

Open the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;ComputerVisionService.cs&lt;/span&gt; file and put the following code inside it.

```code
  using BlazorComputerVision.Models;
  using Microsoft.Azure.CognitiveServices.Vision.ComputerVision.Models;
  using Newtonsoft.Json;
  using Newtonsoft.Json.Linq;
  using System;
  using System.Net.Http;
  using System.Net.Http.Headers;
  using System.Text;
  using System.Threading.Tasks;
  namespace BlazorComputerVision.Data
  {
      public class ComputerVisionService
      {
          static string subscriptionKey;
          static string endpoint;
          static string uriBase;
          public ComputerVisionService()
          {
              subscriptionKey = &quot;88b4cb369bcc4fc7bae5595f45400d45&quot;;
              endpoint = &quot;https://girishblazorocrdemo.cognitiveservices.azure.com/&quot;;
              uriBase = endpoint + &quot;vision/v2.1/ocr&quot;;
          }
          public async Task&lt;OcrResultDTO&gt; GetTextFromImage(byte[] imageFileBytes)
          {
              StringBuilder sb = new StringBuilder();
              OcrResultDTO ocrResultDTO = new OcrResultDTO();
              try
              {
                  string JSONResult = await ReadTextFromStream(imageFileBytes);
                  OcrResult ocrResult = JsonConvert.DeserializeObject&lt;OcrResult&gt;(JSONResult);
                  if (!ocrResult.Language.Equals(&quot;unk&quot;))
                  {
                      foreach (OcrLine ocrLine in ocrResult.Regions[0].Lines)
                      {
                          foreach (OcrWord ocrWord in ocrLine.Words)
                          {
                              sb.Append(ocrWord.Text);
                              sb.Append(' ');
                          }
                          sb.AppendLine();
                      }
                  }
                  else
                  {
                      sb.Append(&quot;This language is not supported.&quot;);
                  }
                  ocrResultDTO.DetectedText = sb.ToString();
                  ocrResultDTO.Language = ocrResult.Language;
                  return ocrResultDTO;
              }
              catch
              {
                  ocrResultDTO.DetectedText = &quot;Error occurred. Try again&quot;;
                  ocrResultDTO.Language = &quot;unk&quot;;
                  return ocrResultDTO;
              }
          }
          static async Task&lt;string&gt; ReadTextFromStream(byte[] byteData)
          {
              try
              {
                  HttpClient client = new HttpClient();
                  client.DefaultRequestHeaders.Add(&quot;Ocp-Apim-Subscription-Key&quot;, subscriptionKey);
                  string requestParameters = &quot;language=unk&amp;detectOrientation=true&quot;;
                  string uri = uriBase + &quot;?&quot; + requestParameters;
                  HttpResponseMessage response;
                  using (ByteArrayContent content = new ByteArrayContent(byteData))
                  {
                      content.Headers.ContentType = new MediaTypeHeaderValue(&quot;application/octet-stream&quot;);
                      response = await client.PostAsync(uri, content);
                  }
                  string contentString = await response.Content.ReadAsStringAsync();
                  string result = JToken.Parse(contentString).ToString();
                  return result;
              }
              catch (Exception e)
              {
                  return e.Message;
              }
          }
          public async Task&lt;AvailableLanguage&gt; GetAvailableLanguages()
          {
              string endpoint = &quot;https://api.cognitive.microsofttranslator.com/languages?api-version=3.0&amp;scope=translation&quot;;
              var client = new HttpClient();
              using (var request = new HttpRequestMessage())
              {
                  request.Method = HttpMethod.Get;
                  request.RequestUri = new Uri(endpoint);
                  var response = await client.SendAsync(request).ConfigureAwait(false);
                  string result = await response.Content.ReadAsStringAsync();
                  AvailableLanguage deserializedOutput = JsonConvert.DeserializeObject&lt;AvailableLanguage&gt;(result);
                  return deserializedOutput;
              }
          }
      }
  } 

```

In the constructor of the class, we have initialized the key and the endpoint URL for the OCR API.

Inside the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;ReadTextFromStream&lt;/span&gt; method, we will create a new &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;HttpRequestMessage&lt;/span&gt;. This HTTP request is a Post request. We will pass the subscription key in the header of the request. The OCR API will return a JSON object having each word from the image as well as the detected language of the text.

The &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;GetTextFromImage&lt;/span&gt; method will accept the image data as a byte array and returns an object of type &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;OcrResultDTO&lt;/span&gt;. We will invoke the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;ReadTextFromStream&lt;/span&gt; method and deserialize the response into an object of type &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;OcrResult&lt;/span&gt;. We will then form the sentence by iterating over the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;OcrWord&lt;/span&gt; object.

The &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;GetAvailableLanguages&lt;/span&gt; method will return the list of all the language supported by the Translate Text API. We will set the request URI and create a &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;HttpRequestMessage&lt;/span&gt; which will be a Get request. This request URI will return a JSON object which will be deserialized to an object of type &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;AvailableLanguage&lt;/span&gt;.

## Why do we need to fetch the list of supported languages?

The OCR API returns the language code (e.g. en for English, de for German, etc.) of the detected language. But we cannot display the language code on the UI as it is not user-friendly. Therefore, we need a dictionary to look up the language name corresponding to the language code.

The Azure Computer Vision OCR API supports 25 languages. To know all the languages supported by OCR API see the list of [supported languages](https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/language-support). These languages are a subset of the languages supported by the Azure Translate Text API. Since there is no dedicated API endpoint to fetch the list of languages supported by OCR API, therefore, we are using the Translate Text API endpoint to fetch the list of languages. We will create the language lookup dictionary using the JSON response from this API call and filter the result based on the language code returned by the OCR API.

## Install BlazorInputFile NuGet package
&lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;BlazorInputFile&lt;/span&gt; is a file input component for Blazor applications. It provides the ability to upload single or multiple files to a Blazor app.

Open &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;BlazorComputerVision.csproj&lt;/span&gt; file and add a dependency for the BlazorInputFile package as shown below:

```code
  &lt;ItemGroup&gt;
    &lt;PackageReference Include=&quot;BlazorInputFile&quot; Version=&quot;0.2.0&quot; /&gt;
&lt;/ItemGroup&gt;

```

Open &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;BlazorComputerVision\Pages\_Host.cshtml&lt;/span&gt; file and add the reference for the package’s JavaScript file by adding the following line in the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;head&lt;/span&gt; section.

```code

&lt;script src=&quot;_content/BlazorInputFile/inputfile.js&quot;&gt;&lt;/script&gt;

```
Add the following line in the _Imports.razor file.

```code
  @using BlazorInputFile
```

## Configuring the Service

To make the service available to the components we need to configure it on the server-side app. Open the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;Startup.cs&lt;/span&gt; file. Add the following line inside the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;ConfigureServices&lt;/span&gt; method of Startup class.

```code
 services.AddSingleton&lt;ComputerVisionService&gt;();

```

## Creating the Blazor UI Component

We will add the Razor page in the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;BlazorComputerVision/Pages&lt;/span&gt; folder. By default, we have “Counter” and “Fetch Data” pages provided in our application. These default pages will not affect our application but for the sake of this tutorial, we will delete fetchdata and counter pages from &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;BlazorComputerVision/Pages&lt;/span&gt; folder.

Right-click on the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;BlazorComputerVision/Pages folder&lt;/span&gt; and then select Add &gt;&gt; New Item. An “Add New Item” dialog box will open, select “Visual C#” from the left panel, then select “Razor Component” from the templates panel, put the name as &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;OCR.razor&lt;/span&gt;. Click Add. Refer to the image shown below.

![image info](/img/azure/10/CreateRazorComponent.png)

We will add a code-behind file for this razor page to keep the code and presentation separate. This will allow easy maintenance for the application.  Right-click on the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;BlazorComputerVision/Pages&lt;/span&gt; folder and then select Add &gt;&gt; Class. Name the class as &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;OCR.razor.cs&lt;/span&gt;. The Blazor framework is smart enough to tag this class file to the razor file. Refer to the image shown below.

![image info](/img/azure/10/OCRStuct.png)

## Blazor UI component code behind
Open the  &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;OCR.razor.cs&lt;/span&gt; file and put the following code inside it.

```code
  using Microsoft.AspNetCore.Components;
  using System;
  using System.Collections.Generic;
  using System.Linq;
  using System.Threading.Tasks;
  using System.IO;
  using BlazorComputerVision.Models;
  using BlazorInputFile;
  using BlazorComputerVision.Data;
  namespace BlazorComputerVision.Pages
  {
      public class OCRModel : ComponentBase
      {
          [Inject]
          protected ComputerVisionService computerVisionService { get; set; }
          protected string DetectedTextLanguage;
          protected string imagePreview;
          protected bool loading = false;
          byte[] imageFileBytes;
          const string DefaultStatus = &quot;Maximum size allowed for the image is 4 MB&quot;;
          protected string status = DefaultStatus;
          protected OcrResultDTO Result = new OcrResultDTO();
          private AvailableLanguage availableLanguages;
          private Dictionary&lt;string, LanguageDetails&gt; LanguageList = new Dictionary&lt;string, LanguageDetails&gt;();
          const int MaxFileSize = 4 * 1024 * 1024; // 4MB
          protected override async Task OnInitializedAsync()
          {
              availableLanguages = await computerVisionService.GetAvailableLanguages();
              LanguageList = availableLanguages.Translation;
          }
          protected async Task ViewImage(IFileListEntry[] files)
          {
              var file = files.FirstOrDefault();
              if (file == null)
              {
                  return;
              }
              else if (file.Size &gt; MaxFileSize)
              {
                  status = $&quot;The file size is {file.Size} bytes, this is more than the allowed limit of {MaxFileSize} bytes.&quot;;
                  return;
              }
              else if (!file.Type.Contains(&quot;image&quot;))
              {
                  status = &quot;Please uplaod a valid image file&quot;;
                  return;
              }
              else
              {
                  var memoryStream = new MemoryStream();
                  await file.Data.CopyToAsync(memoryStream);
                  imageFileBytes = memoryStream.ToArray();
                  string base64String = Convert.ToBase64String(imageFileBytes, 0, imageFileBytes.Length);
                  imagePreview = string.Concat(&quot;data:image/png;base64,&quot;, base64String);
                  memoryStream.Flush();
                  status = DefaultStatus;
              }
          }
          protected private async Task GetText()
          {
              if (imageFileBytes != null)
              {
                  loading = true;
                  Result = await computerVisionService.GetTextFromImage(imageFileBytes);
                  if (LanguageList.ContainsKey(Result.Language))
                  {
                      DetectedTextLanguage = LanguageList[Result.Language].Name;
                  }
                  else
                  {
                      DetectedTextLanguage = &quot;Unknown&quot;;
                  }
                  loading = false;
              }
          }
      }
  }

```

We are injecting the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;ComputerVisionService&lt;/span&gt; in this class.

The &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;OnInitializedAsync&lt;/span&gt; is a Blazor lifecycle method which is invoked when the component is initialized. We are invoking the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;GetAvailableLanguages&lt;/span&gt; method from our service inside the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;OnInitializedAsync&lt;/span&gt; method. We will then initialize the variable &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;LanguageList&lt;/span&gt; which is a dictionary to hold the details of available languages.

Inside the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;ViewImage&lt;/span&gt; method, we will check if the uploaded file is an image only and the size is less than 4 MB. We will transfer the uploaded image to the memory stream. We will then convert that memory stream to a byte array. To set the image preview, we will convert the image from byte array to a base64 encoded string. The &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;GetText&lt;/span&gt; method will invoke the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;GetTextFromImage&lt;/span&gt; method from the service and pass the image byte array as an argument. We will search for the language name from the dictionary based on the language code returned from the service. If no language code is available, we will set the language as unknown.

## Blazor UI component template

Open the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;OCR.razor&lt;/span&gt; file and put the following code inside it.

```code
  @page &quot;/computer-vision-ocr&quot;
@inherits OCRModel
&lt;h2&gt;Optical Character Recognition (OCR) Using Blazor and Azure Computer Vision Cognitive Service&lt;/h2&gt;
&lt;div class=&quot;row&quot;&gt;
    &lt;div class=&quot;col-md-5&quot;&gt;
        &lt;textarea disabled class=&quot;form-control&quot; rows=&quot;10&quot; cols=&quot;15&quot;&gt;@Result.DetectedText&lt;/textarea&gt;
        &lt;hr /&gt;
        &lt;div class=&quot;row&quot;&gt;
            &lt;div class=&quot;col-sm-5&quot;&gt;
                &lt;label&gt;&lt;strong&gt; Detected Language :&lt;/strong&gt;&lt;/label&gt;
            &lt;/div&gt;
            &lt;div class=&quot;col-sm-6&quot;&gt;
                &lt;input disabled type=&quot;text&quot; class=&quot;form-control&quot; value=&quot;@DetectedTextLanguage&quot; /&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    &lt;div class=&quot;col-md-5&quot;&gt;
        &lt;div class=&quot;image-container&quot;&gt;
            &lt;img class=&quot;preview-image&quot; src=@imagePreview&gt;
        &lt;/div&gt;
        &lt;InputFile OnChange=&quot;ViewImage&quot; /&gt;
        &lt;p&gt;@status&lt;/p&gt;
        &lt;hr /&gt;
        &lt;button disabled=&quot;@loading&quot; class=&quot;btn btn-primary btn-lg&quot; @onclick=&quot;GetText&quot;&gt;
            @if (loading)
            {
                &lt;span class=&quot;spinner-border spinner-border-sm mr-1&quot;&gt;&lt;/span&gt;
            }
            Extract Text
        &lt;/button&gt;
    &lt;/div&gt;
&lt;/div&gt;
```

We have defined the route for this component. We have inherited the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;OCRModel&lt;/span&gt; class which allows us to access the properties and method of this class from the template. Bootstrap is used for designing the UI. We have a text area to display the detected text and a text box to display the detected language. The image tag is used to show the image preview after uploading the image. The &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;InputFile&lt;/span&gt; component will allow us to upload an image file and invoke the &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;ViewImage&lt;/span&gt; method as we upload the image.

## Add styling for the component

Navigate to &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;BlazorComputerVision\wwwroot\css\site.css&lt;/span&gt; file and add the following style definition inside it.

```code

  .preview-image {
      max-height: 300px;
      max-width: 300px;
  }
  .image-container{
    display: flex;
    padding: 15px;
    align-content: center;
    align-items: center;
    justify-content: center;
    border: 2px dashed skyblue;
  }

```

## Adding the links in Nav Menu

The last step is to add the link of our OCR component in the navigation menu. Open &lt;span style=&quot;color:yellow;background-color:black;&quot;&gt;BlazorComputerVision/Shared/NavMenu.razor&lt;/span&gt; file and add the following code into it.

```code
  &lt;li class=&quot;nav-item px-3&quot;&gt;
    &lt;NavLink class=&quot;nav-link&quot; href=&quot;computer-vision-ocr&quot;&gt;
      &lt;span class=&quot;oi oi-list-rich&quot; aria-hidden=&quot;true&quot;&gt;&lt;/span&gt; Computer Vision
    &lt;/NavLink&gt;
  &lt;/li&gt;
```
Remove the navigation links for Counter and Fetch-data components as they are not required for this application.

## Execution Demo

Press F5 to launch the application. Click on the Computer Vision button on the nav menu on the left. On the next page, upload an image with some text in it and click on the “Extract Text” button. You will see the extracted text in the text area on the left along with the detected language for the text. Refer to the image shown below.

![image info](/img/azure/10/output3.png)

Now we will try to upload an image with some French text on it, you can see the extracted text and the detected language as French. Refer to the image shown below.

![image info](/img/azure/10/output6.png)


## Summary

We have created an optical character recognition (OCR) application using Blazor and the Computer Vision Azure Cognitive Service. We have added the feature of uploading an image file using the BlazorInputFile component. The application is able to extract the printed text from the uploaded image and recognizes the language of the text. The OCR API of the Computer Vision is used which can recognize text in 25 languages.

Get the Source code from [GitHub](https://github.com/girishgodage/BlazorComputerVisionAzureCognitiveServices) and play around to get a better understanding.</content><author><name>Girish Godage</name></author><category term="learning" /><summary type="html">Introduction</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/img/azure/10/output.gif" /></entry><entry><title type="html">Angular 10 Material Datatable Inline HttpClient CRUD Operations using RestFull APIs</title><link href="http://localhost:4000/blog/angular-httpclient-crud-operations-using-restfull-api" rel="alternate" type="text/html" title="Angular 10 Material Datatable Inline HttpClient CRUD Operations using RestFull APIs" /><published>2020-10-27T02:24:00+00:00</published><updated>2020-10-27T02:24:00+00:00</updated><id>http://localhost:4000/blog/Ang10MatDatatableCRUD</id><content type="html" xml:base="http://localhost:4000/blog/angular-httpclient-crud-operations-using-restfull-api">## Angular 10 Material Datatable Inline HttpClient CRUD Operations using RestFull APIs

&gt; In this Angular tutorial, we’ll learn how to use HttpClient module in Angular application to make RESTFull API Ajax calls.

We’ll set up a **new Angular 10 project** and **create API endpoints** to perform **Create, Read, Update and Delete operations using HTTP** methods using a mock server using the &lt;code&gt;**json-server**&lt;/code&gt; package. Using &lt;code&gt;**json-server**&lt;/code&gt; we can create a local JSON file which can act as a database for our application. There is no difference between a local mock server and a real database.

We’ll perform **HTTP operation using API endpoints** to **add, edit, delete and get list of items listed in an Angular Material Datatable**.

This Material Datatable will have action column using which user an **Edit or Delete a row**. There will be a form over the table to **Add or Update existing rows** in 

After implementation, our application will look like this

![image info](/img/angular/12/1.png)

First, let’s have a look at Angular HttpClient and its features.

## What is Angular HttpClient?

A reactive application like Angular, communicate with server databases to fetch data in form of JSON object using Ajax API calls.

These API Ajex calls use XMLHttpRequest service for old browsers or fetch() methods under the hood.

The HttpClient service provided by Angular’s &lt;code&gt;**@angular/common/http**&lt;/code&gt; package provides a simple interface to make HTTP calls with many optimized and efficient browser support features.

Moreover, we can also use RxJS based Observables and operators to handle client-side or server-side errors.

Using Interceptors service we can modify requests and responses of API calls and even cancels them.

**Let’s get started!**

## #Setup Angular CLI

Angular CLI is the most prefered and official way for creating a new Angular project.

Make sure you have installed the latest version on Angular CLI tool on your system.

Run following npm command to install
```

$ npm install -g @angular/cli
```

For this tutorial, we have installed **v10.1.6**

## #Create a new Angular 10 project

Next, create a new Angular project by running following ng command in the terminal

```
$ ng new ang-datatable-app

```
On hitting above command, ng CLI will ask few configurational questions

```

? Would you like to add Angular routing? Yes
? Which stylesheet format would you like to use? CSS
```

Now move to the project folder

```

$ cd ang-datatable-app
```

Run the project by executing below command

```

$ ng serve --open
```
As we have created the Angular project successfully, lets mover further to create a dummy mock JSON server.

## #Setup a Mock JSON Server

For testing and learning HttpClient module, we need to test Http methods, which will communicate to the server by calling Rest APIs.

These RESTFull APIs return JSON data which is then consumed by Angular application. This API JSON data may come from any third-party API, Server Database or any local server database.

Here we will create a dummy mock JSON API server using the &lt;code&gt;**json-server**&lt;/code&gt; package. using this package we can create a mock server using which we can perform all HTTP methods like &lt;code&gt;**GET**&lt;/code&gt;, &lt;code&gt;**POST**&lt;/code&gt;, &lt;code&gt;**PUT**&lt;/code&gt;, &lt;code&gt;**PATCH**&lt;/code&gt; and &lt;code&gt;**DELETE**&lt;/code&gt;.

First, install the&lt;code&gt; **json-server**&lt;/code&gt; package by running bellow npm command in the terminal window:

```
$ npm install -g json-server
```

After that create a new folder API in the project root and place JSON file data.json at 
**~ang-datatable-app/API/data.json**

The **data.json** file will work as RESTfull server. We will add some dummy employeess data. So that will act like a database on which we will perform CRUD operations.

## #Start JSON Server

To start the JSON server using json-server, run following command in a new terminal:&lt;
```

$ json-server --watch ./API/data.json
```
Now you can access our mock server at **http://localhost:3000/employees**

Following are the API URLs available on our server:

* GET /employees - fetch all employees
* GET /employees/: id - fetch a single employee detail by id
* POST /employees - create a new employee
* PUT /employees/: id - update a employee by id
* PATCH /employees/: id - partially update a employee by  id
* DELETE /employees/:id - delete a employee by id

As we are ready with our server, next we will import HttpClientModule in Angular project to use HTTP services.

&gt;# Configure HttpClient in Angular 10 project

Before using HTTP services, we need to import &lt;code&gt;**HttpClientModule**&lt;/code&gt; from &lt;code&gt;**@angular/common/http**&lt;/code&gt; class.


Now open the app.module.ts file, then make the following changes:

```
// app.module.ts

import { BrowserModule } from '@angular/platform-browser';
import { NgModule } from '@angular/core';

import { AppRoutingModule } from './app-routing.module';
import { AppComponent } from './app.component';

import { HttpClientModule } from '@angular/common/http';

@NgModule({
  declarations: [
    AppComponent
  ],
  imports: [
    BrowserModule,
    AppRoutingModule,
    HttpClientModule
  ],
  providers: [],
  bootstrap: [AppComponent]
})
export class AppModule { }
```

We will add **Angular Material Datatable** to perform CRUD operations on Employees data. So let us install and configure Material UI library in our project.

##  #Install and Setup Angular Material

Angular Material is a UI library which provides several easy to use feature components. In this tutorial, we will use Material Datatables to show employees records and perform the various inline operation on employees records.


Run following npm command in terminal to install Material library and answer some configuration answers.

```
$ ng add @angular/material


? Choose a prebuilt theme name, or &quot;custom&quot; for a custom theme: Indigo/Pink        [ Preview: https://material.angular.io?theme=indigo-pink ]
? Set up global Angular Material typography styles? Yes 
? Set up browser animations for Angular Material? Yes

```

To use Material UI components, we need to import modules of components which we are going to use in the application's module so that these will be available in our class components to use.

As we will be using Material Datatables with pagination, so we need to import &lt;code&gt;**MatTableModule**&lt;/code&gt; and &lt;code&gt;**MatPaginatorModule**&lt;/code&gt;.

To update and add employees rows we will add Material Form as well, for that we will also import &lt;code&gt;**FormsModule**&lt;/code&gt;,&lt;code&gt;**ReactiveFormsModule**&lt;/code&gt;, &lt;code&gt;**MatInputModule**&lt;/code&gt;, and &lt;code&gt;**MatButtonModule**&lt;/code&gt; as well
in the **app.module.ts** file as shown below:

```

// app.module.ts

import { BrowserModule } from '@angular/platform-browser';
import { NgModule } from '@angular/core';

import { AppRoutingModule } from './app-routing.module';
import { AppComponent } from './app.component';

import { HttpClientModule } from '@angular/common/http';
import { BrowserAnimationsModule } from '@angular/platform-browser/animations';

import { FormsModule, ReactiveFormsModule } from '@angular/forms';

import { MatTableModule } from '@angular/material/table';
import { MatPaginatorModule } from '@angular/material/paginator';
import { MatInputModule } from '@angular/material/input';
import { MatButtonModule } from '@angular/material/button';


@NgModule({
  declarations: [
    AppComponent    
  ],
  imports: [
    BrowserModule,
    AppRoutingModule,
    HttpClientModule,
    BrowserAnimationsModule,
    FormsModule,
    ReactiveFormsModule,

    // Material Modules 
    MatTableModule,
    MatPaginatorModule,
    MatInputModule,
    MatButtonModule
  ],
  providers: [],
  bootstrap: [AppComponent]
})
export class AppModule { }
```

## #Creating a Service to Communicate Server through HTTP methods

Now we'll create a new service to separate all HTTP methods which will communicate to server and do CRUD operations.


Let's create a new serve HttpDataService under services folder by running following ng command in the terminal window:

```
$ ng generate service services/http-data
```

Above &lt;code&gt;**generate**&lt;/code&gt; command will create the &lt;code&gt;**HttpDataService**&lt;/code&gt; for us at this location **~src/app/services/http-data.service.ts**

Also, create an **Interface class** for *Employees* data by running following command defining the type of values for employee item.

```
$ ng generate class models/Employee

```

then replace the following content in the newly created file &quot;~/models/**employee.ts**&quot;


```
export class Employee {
    id: number;
    userId: string;
    jobTitleName: string;
    firstName: string;
    lastName: string;
    preferredFullName: string;
    employeeCode: string;
    region: string
    phoneNumber: string;
    emailAddress: string;
}
```

Our service will be going to play an important role in maintaining a connection with the server. Let us dive deep into this file and check what it will have?

Add the server API URL for end-points and define in the &lt;code&gt;**base_path**&lt;/code&gt; variable. This is the path which opens up on running our &lt;code&gt;**json-server**&lt;/code&gt;

```

  // API path
  base_path = 'http://localhost:3000/employees';
```  
*Note:* Make sure your server is still running.

We'll import these three classes

&lt;code&gt;**HttpClient**&lt;/code&gt; : This class provides HTTP methods like &lt;code&gt;**get()**&lt;/code&gt;, &lt;code&gt;**post()**&lt;/code&gt;, &lt;code&gt;**put()**&lt;/code&gt; and &lt;code&gt;**delete()**&lt;/code&gt;.

&lt;code&gt;**HttpHeaders**&lt;/code&gt;: For setting request headers in HTTP calls we use this class.

```

  // Http Options
  httpOptions = {
    headers: new HttpHeaders({
      'Content-Type': 'application/json'
    })
  }
```  
&lt;code&gt;**HttpErrorResponse**&lt;/code&gt;: Used to efficiently handle errors from client-side or server-side.

```
  // Handle API errors
  handleError(error: HttpErrorResponse) {
    if (error.error instanceof ErrorEvent) {
      // A client-side or network error occurred. Handle it accordingly.
      console.error('An error occurred:', error.error.message);
    } else {
      // The backend returned an unsuccessful response code.
      // The response body may contain clues as to what went wrong,
      console.error(
        `Backend returned code ${error.status}, ` +
        `body was: ${error.error}`);
    }
    // return an observable with a user-facing error message
    return throwError(
      'Something bad happened; please try again later.');
  };
```

## #RxJs functions and operators to the rescue&lt;/span&gt;
&lt;/h4&gt;

The RxJs library provides many useful function and operator which we will use in our service:

&lt;code&gt;**Observables**&lt;/code&gt;: Observables are used to perform asynchronous tasks like HTTP calls. We can subscribe them to get success or error response. They provide several other features file cancellations and continuous event retrieval, unlike promises.


&lt;code&gt;**throwError**&lt;/code&gt;: This method is used to intentionally throw an error with a message when an HTTP request fails.

&lt;code&gt;**retry()**&lt;/code&gt;: The retry operator is used to make HTTP call again for the number of times specified when a call fails due to network server issues.

&lt;code&gt;**catchError()**&lt;/code&gt;: This method catches the error and throws to errorHandler

##  #Defining CRUD Methods


Now we will add the methods to do CRUD operation on emloyees data in our mock server which we created using &lt;code&gt;**json-server**&lt;/code&gt;.


### Create an Employee

The new employee will be created using the &lt;code&gt;**post()**&lt;/code&gt; method

```
  // Create a new item
  createItem(item): Observable&lt;Employee&gt; {
    return this.http
      .post&lt;Employee&gt;(this.base_path, JSON.stringify(item), this.httpOptions)
      .pipe(
        retry(2),
        catchError(this.handleError)
      )
  }
```

The &lt;code&gt;**createItem()**&lt;/code&gt; method is accepting &lt;code&gt;**item**&lt;/code&gt; attribute with employee details to add.

### Retrieve Employee Details

To fetch single employee details we use &lt;code&gt;**get()**&lt;/code&gt; method with employee &lt;code&gt;**id**&lt;/code&gt; whose detail needs to be checked.

```
 // Get single employee data by ID
  getItem(id): Observable&lt;Employee&gt; {
    return this.http
      .get&lt;Employee&gt;(this.base_path + '/' + id)
      .pipe(
        retry(2),
        catchError(this.handleError)
      )
  }

```

### Retrieve All Employees

Similarly, we will make &lt;code&gt;**get**&lt;/code&gt; call to fetch all employees list

```
  // Get employees data
  getList(): Observable&lt;Employee&gt; {
    return this.http
      .get&lt;Employee&gt;(this.base_path)
      .pipe(
        retry(2),
        catchError(this.handleError)
      )
  }
```  
### Update single employee

The &lt;code&gt;**put()**&lt;/code&gt; method will update single employee with id passed

```
  // Update item by id
  updateItem(id, item): Observable&lt;Employee&gt; {
    return this.http
      .put&lt;Employee&gt;(this.base_path + '/' + id, JSON.stringify(item), this.httpOptions)
      .pipe(
        retry(2),
        catchError(this.handleError)
      )
  }
```  
### Delete a single employee

The &lt;code&gt;**delete()**&lt;/code&gt; HTTP method will delete a single record whose id is passed

```

  // Delete item by id
  deleteItem(id) {
    return this.http
      .delete&lt;Employee&gt;(this.base_path + '/' + id, this.httpOptions)
      .pipe(
        retry(2),
        catchError(this.handleError)
      )
  }
```

  After combining all explained code the final **http-data.service.ts** file will look like this:

```

// http-data.servie.ts
import { Injectable } from '@angular/core';
import { HttpClient, HttpHeaders, HttpErrorResponse } from '@angular/common/http';
import { Employee } from '../models/employee';
import { Observable, throwError } from 'rxjs';
import { retry, catchError } from 'rxjs/operators';

@Injectable({
  providedIn: 'root'
})
export class HttpDataService {


  // API path
  base_path = 'http://localhost:3000/employees';

  constructor(private http: HttpClient) { }

  // Http Options
  httpOptions = {
    headers: new HttpHeaders({
      'Content-Type': 'application/json'
    })
  }

  // Handle API errors
  handleError(error: HttpErrorResponse) {
    if (error.error instanceof ErrorEvent) {
      // A client-side or network error occurred. Handle it accordingly.
      console.error('An error occurred:', error.error.message);
    } else {
      // The backend returned an unsuccessful response code.
      // The response body may contain clues as to what went wrong,
      console.error(
        `Backend returned code ${error.status}, ` +
        `body was: ${error.error}`);
    }
    // return an observable with a user-facing error message
    return throwError(
      'Something bad happened; please try again later.');
  };


  // Create a new item
  createItem(item): Observable&lt;Employee&gt; {
    return this.http
      .post&lt;Employee&gt;(this.base_path, JSON.stringify(item), this.httpOptions)
      .pipe(
        retry(2),
        catchError(this.handleError)
      )
  }

  // Get single employee data by ID
  getItem(id): Observable&lt;Employee&gt; {
    return this.http
      .get&lt;Employee&gt;(this.base_path + '/' + id)
      .pipe(
        retry(2),
        catchError(this.handleError)
      )
  }

  // Get employees data
  getList(): Observable&lt;Employee&gt; {
    return this.http
      .get&lt;Employee&gt;(this.base_path)
      .pipe(
        retry(2),
        catchError(this.handleError)
      )
  }

  // Update item by id
  updateItem(id, item): Observable&lt;Employee&gt; {
    return this.http
      .put&lt;Employee&gt;(this.base_path + '/' + id, JSON.stringify(item), this.httpOptions)
      .pipe(
        retry(2),
        catchError(this.handleError)
      )
  }

  // Delete item by id
  deleteItem(id) {
    return this.http
      .delete&lt;Employee&gt;(this.base_path + '/' + id, this.httpOptions)
      .pipe(
        retry(2),
        catchError(this.handleError)
      )
  }
}

```
## #Create new pages

To show employees data in a table,&amp;nbsp; we will create a new employees component and update the&lt;strong&gt; app-routing.module.ts&lt;/strong&gt; file to open &lt;code&gt;/employees&lt;/code&gt; page on application load.

Create the &lt;code&gt;**EmployeesComponent**&lt;/code&gt;
by running below generate command:
```

$ ng generate component pages/employees
```

Setup the App Routing Module
Now update the **app-routing.module.ts**file with below code.

```

// app-routing.module.ts
import { NgModule } from '@angular/core';
import { Routes, RouterModule } from '@angular/router';
import { EmployeesComponent } from './pages/employees/employees.component';


const routes: Routes = [
  {
    path: '',
    redirectTo: '/employees',
    pathMatch: 'full'
  },
  {
    path: 'employees',
    component: EmployeesComponent
  }
];

@NgModule({
  imports: [RouterModule.forRoot(routes)],
  exports: [RouterModule]
})
export class AppRoutingModule { }
```

## #Using HttpDataService in Employees Page

As we defined our HttpDataService as &lt;code&gt;**providedIn: 'root'**&lt;/code&gt;so we can directly use it in our Angular application. This will share a single instance across the application.

To use service methods in our employee's page at **~src/app/pages/employees/employees.component.ts**, we need to &lt;code&gt;**impor**t&lt;/code&gt; it and then add in component the contractor() method as shown below:

```
...
import { HttpDataService } from 'src/app/services/http-data.service';

@Component({
  selector: 'app-employees',
  templateUrl: './employees.component.html',
  styleUrls: ['./employees.component.css']
})
export class EmployeesComponent implements OnInit {

  constructor(private httpDataService: HttpDataService) { }

  ...
}

```
##  #Adding Angular Material Datatable


Next, we will add a Datatable with Employees columns and an extra Actions column where we will do inline Edit, Delete and Update operations.

For creating the Material datatable, the &lt;code&gt;**mat-table**&lt;/code&gt; directive is used. We are also adding pagination by appending the &lt;code&gt;**mat-paginator**&lt;/code&gt; directive just after ending &lt;code&gt;**&lt;/table&gt;**&lt;/code&gt; tag.

Update the **employees.component.html** file with below code to build a Material datatable:

```

        &lt;!-- Form to edit/add row --&gt;

        &lt;table mat-table [dataSource]=&quot;dataSource&quot; class=&quot;mat-elevation-z8&quot;&gt;

    &lt;ng-container matColumnDef=&quot;id&quot;&gt;
        &lt;th mat-header-cell *matHeaderCellDef&gt; #Id &lt;/th&gt;
        &lt;td mat-cell *matCellDef=&quot;let element&quot;&gt; {{element.id}} &lt;/td&gt;
    &lt;/ng-container&gt;

    &lt;ng-container matColumnDef=&quot;userId&quot;&gt;
        &lt;th mat-header-cell *matHeaderCellDef&gt; User Id &lt;/th&gt;
        &lt;td mat-cell *matCellDef=&quot;let element&quot;&gt; {{element.userId}} &lt;/td&gt;
    &lt;/ng-container&gt;

    &lt;ng-container matColumnDef=&quot;jobTitleName&quot;&gt;
        &lt;th mat-header-cell *matHeaderCellDef&gt; jobTitle Name &lt;/th&gt;
        &lt;td mat-cell *matCellDef=&quot;let element&quot;&gt; {{element.jobTitleName}} &lt;/td&gt;
    &lt;/ng-container&gt;

    &lt;ng-container matColumnDef=&quot;firstName&quot;&gt;
        &lt;th mat-header-cell *matHeaderCellDef&gt; First Name &lt;/th&gt;
        &lt;td mat-cell *matCellDef=&quot;let element&quot;&gt; {{element.firstName}} &lt;/td&gt;
    &lt;/ng-container&gt;

    &lt;ng-container matColumnDef=&quot;lastName&quot;&gt;
        &lt;th mat-header-cell *matHeaderCellDef&gt; Last Name &lt;/th&gt;
        &lt;td mat-cell *matCellDef=&quot;let element&quot;&gt; {{element.lastName}} &lt;/td&gt;
    &lt;/ng-container&gt;

    &lt;ng-container matColumnDef=&quot;preferredFullName&quot;&gt;
        &lt;th mat-header-cell *matHeaderCellDef&gt; Preferred FullName &lt;/th&gt;
        &lt;td mat-cell *matCellDef=&quot;let element&quot;&gt; {{element.preferredFullName}} &lt;/td&gt;
    &lt;/ng-container&gt;

    &lt;ng-container matColumnDef=&quot;employeeCode&quot;&gt;
        &lt;th mat-header-cell *matHeaderCellDef&gt; Employee Code &lt;/th&gt;
        &lt;td mat-cell *matCellDef=&quot;let element&quot;&gt; {{element.employeeCode}} &lt;/td&gt;
    &lt;/ng-container&gt;

    &lt;ng-container matColumnDef=&quot;region&quot;&gt;
        &lt;th mat-header-cell *matHeaderCellDef&gt; Region &lt;/th&gt;
        &lt;td mat-cell *matCellDef=&quot;let element&quot;&gt; {{element.region}} &lt;/td&gt;
    &lt;/ng-container&gt;

    &lt;ng-container matColumnDef=&quot;phoneNumber&quot;&gt;
        &lt;th mat-header-cell *matHeaderCellDef&gt; Phone Number &lt;/th&gt;
        &lt;td mat-cell *matCellDef=&quot;let element&quot;&gt; {{element.phoneNumber}} &lt;/td&gt;
    &lt;/ng-container&gt;

    &lt;ng-container matColumnDef=&quot;emailAddress&quot;&gt;
        &lt;th mat-header-cell *matHeaderCellDef&gt; Email Address &lt;/th&gt;
        &lt;td mat-cell *matCellDef=&quot;let element&quot;&gt; {{element.emailAddress}} &lt;/td&gt;
    &lt;/ng-container&gt;

    &lt;ng-container matColumnDef=&quot;actions&quot;&gt;
        &lt;th mat-header-cell *matHeaderCellDef&gt; Actions &lt;/th&gt;
        &lt;td mat-cell *matCellDef=&quot;let element&quot;&gt;
            &lt;a href=&quot;javascript:void(0)&quot; (click)=&quot;editItem(element)&quot;&gt;Edit&lt;/a&gt; |
            &lt;a href=&quot;javascript:void(0)&quot; (click)=&quot;deleteItem(element.id)&quot;&gt;Delete&lt;/a&gt;
        &lt;/td&gt;
    &lt;/ng-container&gt;

    &lt;tr mat-header-row *matHeaderRowDef=&quot;displayedColumns&quot;&gt;&lt;/tr&gt;
    &lt;tr mat-row *matRowDef=&quot;let row; columns: displayedColumns;&quot;
        [ngClass]=&quot;{'editable-row': employeeData.id === row.id}&quot;&gt;&lt;/tr&gt;
&lt;/table&gt;
&lt;mat-paginator [pageSize]=&quot;5&quot; [pageSizeOptions]=&quot;[5, 10, 15]&quot; showFirstLastButtons&gt;&lt;/mat-paginator&gt;
&lt;/div&gt;

```

In the last &lt;code&gt;**actions**&lt;/code&gt; column there are two actions to **Edit** with &lt;code&gt;**editEmployee()**&lt;/code&gt; method and **Delete** with&lt;code&gt; **deleteEmployee()**&lt;/code&gt; method for the row.

To add a new row or update the data in the existing row we will add a form above table.

```
    &lt;form (submit)=&quot;onSubmit()&quot; #employeeForm=&quot;ngForm&quot;&gt;
        
        &lt;mat-form-field&gt;
            &lt;input matInput placeholder=&quot;User Id&quot; name=&quot;userId&quot; required [(ngModel)]=&quot;employeeData.userId&quot;&gt;
        &lt;/mat-form-field&gt;
        &lt;mat-form-field&gt;
            &lt;input matInput placeholder=&quot;Job TitleName&quot; name=&quot;jobTitleName&quot; required [(ngModel)]=&quot;employeeData.jobTitleName&quot;&gt;
        &lt;/mat-form-field&gt;
        &lt;mat-form-field&gt;
            &lt;input matInput placeholder=&quot;first Name&quot; name=&quot;firstName&quot; required [(ngModel)]=&quot;employeeData.firstName&quot;&gt;
        &lt;/mat-form-field&gt;
        &lt;mat-form-field&gt;
            &lt;input matInput placeholder=&quot;Last Name&quot; name=&quot;lastName&quot; required [(ngModel)]=&quot;employeeData.lastName&quot;&gt;
        &lt;/mat-form-field&gt;
        &lt;mat-form-field&gt;
            &lt;input matInput placeholder=&quot;Preferred FullName&quot; name=&quot;preferredFullName&quot; required [(ngModel)]=&quot;employeeData.preferredFullName&quot;&gt;
        &lt;/mat-form-field&gt;        
        &lt;mat-form-field&gt;
            &lt;input matInput placeholder=&quot;Employee Code&quot; name=&quot;employeeCode&quot; required [(ngModel)]=&quot;employeeData.employeeCode&quot;&gt;
        &lt;/mat-form-field&gt;
        &lt;mat-form-field&gt;
            &lt;input matInput placeholder=&quot;Region&quot; name=&quot;region&quot; required [(ngModel)]=&quot;employeeData.region&quot;&gt;
        &lt;/mat-form-field&gt;
        &lt;mat-form-field&gt;
            &lt;input matInput placeholder=&quot;Phone Number&quot; name=&quot;phoneNumber&quot; required [(ngModel)]=&quot;employeeData.phoneNumber&quot;&gt;
        &lt;/mat-form-field&gt;
        &lt;mat-form-field&gt;
            &lt;input matInput placeholder=&quot;Email Address&quot; name=&quot;emailAddress&quot; required [(ngModel)]=&quot;employeeData.emailAddress&quot;&gt;
        &lt;/mat-form-field&gt;

        &lt;ng-container *ngIf=&quot;isEditMode; else elseTemplate&quot;&gt;
            &lt;button mat-button color=&quot;primary&quot;&gt;Update&lt;/button&gt;
            &lt;a mat-button color=&quot;warn&quot; (click)=&quot;cancelEdit()&quot;&gt;Cancel&lt;/a&gt;
        &lt;/ng-container&gt;
        &lt;ng-template #elseTemplate&gt;
            &lt;button mat-button color=&quot;primary&quot;&gt;Add&lt;/button&gt;
        &lt;/ng-template&gt;

    &lt;/form&gt;
    

```

The text in form submit button will change based on the boolean value in the &lt;code&gt;**isEditMode**&lt;/code&gt; variable.

## #Update Component Class

After adding Material datatable and Form, let us update **employees.component.ts** file with required methods.

First, initialize the Template driven form with the &lt;code&gt;**NgForm**&lt;/code&gt;

```
  @ViewChild('employeeForm', { static: false })
  employeeForm: NgForm;
```

Import the &lt;code&gt;Employee&lt;/code&gt; class which we created and define a new variable &lt;code&gt;employeeData&lt;/code&gt; of type &lt;code&gt;Employee&lt;/code&gt;

```

employeeData: Employee;

```
Then define the &lt;code&gt;**dataSource**&lt;/code&gt; and &lt;code&gt;**displayedColumns**&lt;/code&gt; with &lt;code&gt;**MatPaginator**&lt;/code&gt; class to build our Datatable

```
  dataSource = new MatTableDataSource();
  displayedColumns: string[] = ['id', 'userId', 'jobTitleName', 'firstName','lastName','preferredFullName','employeeCode','region', 'phoneNumber','emailAddress','actions'];
  @ViewChild(MatPaginator, { static: true }) paginator: MatPaginator;
  
```  
Then we will add methods to Add, Delete, Edit, Update and Get Employees list in the class file as shown below:

```
...
  getAllEmployees() {
    this.httpDataService.getList().subscribe((response: any) =&gt; {
      this.dataSource.data = response;
    });
  }

  editItem(element) {
    this.employeeData = _.cloneDeep(element);
    this.isEditMode = true;
  }

  cancelEdit() {
    this.isEditMode = false;
    this.employeeForm.resetForm();
  }

  deleteItem(id) {
    this.httpDataService.deleteItem(id).subscribe((response: any) =&gt; {

      // Approach #1 to update datatable data on local itself without fetching new data from server
      this.dataSource.data = this.dataSource.data.filter((o: Employee) =&gt; {
        return o.id !== id ? o : false;
      })

      console.log(this.dataSource.data);

      // Approach #2 to re-call getAllEmployees() to fetch updated data
      // this.getAllEmployees()
    });
  }

  addEmployee() {
    this.httpDataService.createItem(this.employeeData).subscribe((response: any) =&gt; {
      this.dataSource.data.push({ ...response })
      this.dataSource.data = this.dataSource.data.map(o =&gt; {
        return o;
      })
    });
  }

  updateEmployee() {
    this.httpDataService.updateItem(this.employeeData.id, this.employeeData).subscribe((response: any) =&gt; {

      // Approach #1 to update datatable data on local itself without fetching new data from server
      this.dataSource.data = this.dataSource.data.map((o: Employee) =&gt; {
        if (o.id === response.id) {
          o = response;
        }
        return o;
      })

      // Approach #2 to re-call getAllEmployees() to fetch updated data
      // this.getAllEmployees()

      this.cancelEdit()

    });
  }
...

``` 

We are calling &lt;code&gt;HttpDataService&lt;/code&gt; methods to communicate with our &lt;code&gt;json-server&lt;/code&gt;
After adding the above method the final **employees.component.ts** file will look like this:

```

// employees.component.ts
import { Component, OnInit, ViewChild } from '@angular/core';
import { NgForm } from '@angular/forms';
import { HttpDataService } from 'src/app/services/http-data.service';
import * as _ from 'lodash';
import { Employee } from 'src/app/models/employee';
import { MatPaginator } from '@angular/material/paginator';
import { MatTableDataSource } from '@angular/material/table';

@Component({
  selector: 'app-employees',
  templateUrl: './employees.component.html',
  styleUrls: ['./employees.component.css']
})
export class EmployeesComponent implements OnInit {

  @ViewChild('employeeForm', { static: false })
  employeeForm: NgForm;

  employeeData: Employee;

  dataSource = new MatTableDataSource();
  displayedColumns: string[] = ['id', 'userId', 'jobTitleName', 'firstName','lastName','preferredFullName','employeeCode','region', 'phoneNumber','emailAddress','actions'];
  @ViewChild(MatPaginator, { static: true }) paginator: MatPaginator;

  isEditMode = false;

  constructor(private httpDataService: HttpDataService) {
    this.employeeData = {} as Employee;
   }

  ngOnInit(): void {
    // Initializing Datatable pagination
    this.dataSource.paginator = this.paginator;

    // Fetch All Employees on Page load
    this.getAllEmployees();
  }

  getAllEmployees(){
    this.httpDataService.getList().subscribe((response: any) =&gt; {
      this.dataSource.data = response;
    });
  }

  editItem(element) {
    this.employeeData = _.cloneDeep(element);
    this.isEditMode = true;
  }

  cancelEdit() {
    this.isEditMode = false;
    this.employeeForm.resetForm();
  }

  deleteItem(id) {
    this.httpDataService.deleteItem(id).subscribe((response: any) =&gt; {

      // Approach #1 to update datatable data on local itself without fetching new data from server
      this.dataSource.data = this.dataSource.data.filter((o: Employee) =&gt; {
        return o.id !== id ? o : false;
      })

      console.log(this.dataSource.data);

      // Approach #2 to re-call getAllEmployees() to fetch updated data
      // this.getAllEmployees()
    });
  }

  addEmployee() {
    this.httpDataService.createItem(this.employeeData).subscribe((response: any) =&gt; {
      this.dataSource.data.push({ ...response })
      this.dataSource.data = this.dataSource.data.map(o =&gt; {
        return o;
      })
    });
  }

  updateEmployee() {
    this.httpDataService.updateItem(this.employeeData.id, this.employeeData).subscribe((response: any) =&gt; {

      // Approach #1 to update datatable data on local itself without fetching new data from server
      this.dataSource.data = this.dataSource.data.map((o: Employee) =&gt; {
        if (o.id === response.id) {
          o = response;
        }
        return o;
      })

      // Approach #2 to re-call getAllEmployees() to fetch updated data
      // this.getAllEmployees()

      this.cancelEdit()

    });
  }

  onSubmit() {
    if (this.employeeForm.form.valid) {
      if (this.isEditMode)
        this.updateEmployee()
      else
        this.addEmployee();
    } else {
      console.log('Enter valid data!');
    }
  }

}

```

That's it now run you server by executing &lt;code&gt;**$ json-server --watch ./API/data.json**&lt;/code&gt; then run Angular application in another terminal by executing &lt;code&gt;**$ ng serve --open**&lt;/code&gt;
You can get source code of this tutorial in my GitHub repo [here](https://github.com/girishgodage/ang10MatDatatabeCrud)

**Conclusion**: In this tutorial, we get to know how to use Http services to make server communication, use get, post, put and delete methods on data server. We use RxJs methods and operators to handle errors and network issues using &lt;code&gt;retry()&lt;/code&gt; . Added Angular Material UI library to show data rows in a Datatable. In the Material Datatable, we performed CRUD operation using Inline approach</content><author><name>Girish Godage</name></author><category term="learning" /><category term="programming" /><summary type="html">Angular 10 Material Datatable Inline HttpClient CRUD Operations using RestFull APIs</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/img/angular_logo.png" /></entry><entry><title type="html">Azure Static Web Apps</title><link href="http://localhost:4000/blog/azure-static-web-apps" rel="alternate" type="text/html" title="Azure Static Web Apps" /><published>2020-10-19T14:44:00+00:00</published><updated>2020-10-19T14:44:00+00:00</updated><id>http://localhost:4000/blog/azure-static-web-apps</id><content type="html" xml:base="http://localhost:4000/blog/azure-static-web-apps">## Introduction

Azure Static Web Apps is a service that automatically builds and deploys full stack web apps to Azure from a GitHub repository.

![image info](/img/azure/8/static-apps-overview.png)

The workflow of **Azure Static Web Apps** is tailored to a developer's daily workflow. Apps are built and deployed based off GitHub interactions.

When you create an Azure Static Web Apps resource, Azure sets up a **GitHub Actions workflow** in the app's source code repository that monitors a branch of your choice. Every time you **push commits** or **accept pull requests** into the watched branch, the *GitHub Action automatically builds and deploys your app and its API to Azure*.

**Static web apps** are commonly built using libraries and frameworks like **Angular, React, Svelte, Vue, or Blazor**. These apps include **HTML, CSS, JavaScript, and image assets** that make up the application. *With a traditional web server, these assets are served from a single server alongside any required API endpoints*.

With **Static Web Apps**, s*tatic assets are separated from a traditional web server and are instead served from points geographically distributed around the world*.

This distribution makes serving files much faster as files are physically closer to end users. In addition, *API endpoints are hosted using a serverless architecture*, which avoids the need for a full back-end server all together.

## Key features
* **Web hosting** for static content like HTML, CSS, JavaScript, and images.
* **Integrated API** support provided by Azure Functions.
First-class GitHub integration where repository changes trigger builds and deployments.
* **Globally distributed** static content, putting content closer to your users.
* **Free SSL certificates**, which are automatically renewed.
* **Custom domains** to provide branded customizations to your app.
* **Seamless security** model with a reverse-proxy when calling APIs, which requires no CORS configuration.
* **Authentication provider integrations** with Azure Active Directory, Facebook, Google, GitHub, and Twitter.
* **Customizable authorization** role definition and assignments.
* **Back-end routing rules** enabling full control over the content and routes you serve.
* **Generated staging versions** powered by pull requests enabling preview versions of your site before publishing.
  
## What you can do with Static Web Apps

* **Build modern web applications** with *JavaScript frameworks and libraries like Angular, React, Svelte, Vue, or using Blazor to create WebAssembly applications, with an Azure Functions back-end*.
* **Publish static sites** with frameworks like Gatsby, Hugo, VuePress.
* **Deploy web applications** with frameworks like Next.js and Nuxt.js.

## Building your first static web app

Azure Static Web Apps publishes a website to a production environment by building apps from a GitHub repository. In this quickstart, you deploy a web application to Azure Static Web apps using the Visual Studio Code extension.

If you don't have an Azure subscription, [create a free trial account](https://azure.microsoft.com/free).
 
## Prerequisites
* [GitHub](https://github.com/) account
* [Azure](https://portal.azure.com/) account
* [Visual Studio Code](https://code.visualstudio.com/)
* [Azure Static Web Apps extension for Visual Studio Code](https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-azurestaticwebapps)

## Create a repository

This article uses a GitHub template repository to make it easy for you to get started. The template features a starter app used to deploy using Azure Static Web Apps.

1. Make sure you're signed in to GitHub and navigate to the following location to create a new repository:
  * a. https://github.com/staticwebdev/vanilla-basic/generate
  
2. Name your repository my-first-static-web-app

&gt; Note:Azure Static Web Apps requires at least one HTML file to create a web app. The repository you create in this step includes a single index.html file.

Select **Create repository from template**.

![image info](/img/azure/8/create-template.png)

## Clone the repository

With the repository created in your GitHub account, clone the project to your local machine using the following command.

```bash

git clone https://github.com/&lt;YOUR_GITHUB_ACCOUNT_NAME&gt;/my-first-static-web-app.git
```
Make sure to replace &lt;YOUR_GITHUB_ACCOUNT_NAME&gt; with your GitHub username.

Next, open Visual Studio Code and go to **File &gt; Open Folder** to open the repository you just cloned to your machine in the editor.

## Create a static web app

1. Inside Visual Studio Code, select the Azure logo in the Activity Bar to open the Azure extensions window.
   
   ![image info](/img/azure/8/extension-azure-logo.png)

&gt; Note:
**Azure and GitHub sign in are required**. If you are not already signed in to Azure and GitHub from Visual Studio Code, the extension will prompt you to sign in to both during the creation process.

2. Place your mouse over the Static Web Apps label and select the plus sign.

![image info](/img/azure/8/extension-create-button.png)

3. The command palate opens at the top of the editor and prompts you to name your application.
    Type **my-first-static-web-app** and press **Enter**.

![image info](/img/azure/8/extension-create-app.png)

4. Select the master branch and press Enter.

![image info](/img/azure/8/extension-branch.png)

5. Select / as the location for the application code and press Enter.


![image info](/img/azure/8/extension-app-location.png)

6. The extension is looking for the location of the API in your application. This article doesn't implement an API. Select **Skip for now** and press **Enter**.

![image info](/img/azure/8/extension-api-location.png)

7. Select the location where files are built for production in your app
   
   Clear the box and press Enter.

![image info](/img/azure/8/extension-artifact-no-framework.png)

8. Select a location nearest you and press Enter.

![image info](/img/azure/8/extension-location.png)

9.Once the app is created, a confirmation notification is shown in Visual Studio Code.

![image info](/img/azure/8/extension-confirmation.png)

10. In the Visual Studio Code Explorer window, return to the Static Web Apps section and right-click on Production and select Open in Portal to view app in the Azure portal.

![image info](/img/azure/8/extension-open-in-portal.png)

## View the website

There are two aspects to deploying a static app. The first provisions the underlying Azure resources that make up your app. The second is a GitHub Actions workflow that builds and publishes your application.

Before you can navigate to your new static site, the deployment build must first finish running.

The Static Web Apps overview window displays a series of links that help you interact with your web app.
    
![image info](/img/azure/8/overview-window.png)

1. *Clicking on the banner that says, Click here to check the status of your GitHub Actions runs* takes you to the GitHub Actions running against your repository. Once you verify the deployment job is complete, then you can navigate to your website via the generated URL.

2. Once GitHub Actions workflow is complete, you can click on the URL link to open the website in new tab.

## Clean up resources
If you're not going to continue to use this application, you can delete the Azure Static Web Apps instance through the extension.

In the Visual Studio Code Explorer window, return to the Static Web Apps section and right-click on **my-first-static-web-app** and select **Delete**.

![image info](/img/azure/8/extension-delete.png)



## Add an API to Azure Static Web Apps Preview with Azure Functions

You can add **serverless APIs** to Azure Static Web Apps via integration with Azure Functions. This article demonstrates how to add and deploy an API to an Azure Static Web Apps site.

Prerequisites
* Azure account with an active subscription.
  If you don't have an account, [you can create one for free](https://azure.microsoft.com/free).
* [Visual Studio Code](https://code.visualstudio.com/)
* [Azure Functions extension](https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-azurefunctions) for Visual Studio Code
* [Live Server Visual Studio Code extension](https://marketplace.visualstudio.com/items?itemName=ritwickdey.LiveServer).
* [Node.js](https://nodejs.org/download/) to run the API app locally

## Create a Git repository

The following steps demonstrate how to create a new repository and clone the files to your computer.

1. Make sure you are logged in to GitHub and, navigate to https://github.com/staticwebdev/vanilla-basic/generate to create a new repository.

2. In the Repository name box, enter my-vanilla-api.

3. Click Create repository from template.
   
![image info](/img/azure/8/create-repository.png)

Once your project is created, copy the URL in your browser for the new repository. You use this URL in Visual Studio Code to clone the Git repository.

1. Press **F1** to open command in the Command Palette.

2. Paste the URL into the *Git: Clone* prompt, and press **Enter**.

![image info](/img/azure/8/vscode-git-0.png)

Follow the prompts to select a repository location to clone the project.

## Create the API

Next, you create an Azure Functions project as the application's API.

* Inside the **my-vanilla-api** project, create a sub-folder named **api**.
  
* Press **F1** to open the Command Palette
  
* Type **Azure Functions: Create New Project**...
  
* Press **Enter**
  
* Choose **Browse**
  
* Select the **api** folder as the directory for your  project workspace
  
* Choose **Select**

![image info](/img/azure/8/create-azure-functions-vscode-1.png)

8. Provide the following information at the prompts:

* Select a language: Choose JavaScript
* Select a template for your project's first function: Choose HTTP trigger
* Provide a function name: Enter GetMessage
* Authorization level: Choose Anonymous, which enables anyone to call your function endpoint.
    - To learn about authorization levels, see Authorization keys.
  
Visual Studio Code generates an Azure Functions project with an HTTP triggered function.

Your app now has a project structure similar to the following example.

```

├── api
│   ├── GetMessage
│   │   ├── function.json
│   │   ├── index.js
│   │   └── sample.dat
│   ├── host.json
│   ├── local.settings.json
│   ├── package.json
│   └── proxies.json
├── index.html
├── readme.md
└── styles.css
```

Next, you'll change the **GetMessage** function to return a message to the front-end.

1. Update the GetMessage function under api/GetMessage/index.js with the following code.

``` java script

module.exports = async function (context, req) {
  context.res = {
    body: {
      text: &quot;Hello from the API&quot;
    }
  };
};
```

2. Update the GetMessage configuration under api/GetMessage/function.json with the following settings.

```

{
  &quot;bindings&quot;: [
    {
      &quot;authLevel&quot;: &quot;anonymous&quot;,
      &quot;type&quot;: &quot;httpTrigger&quot;,
      &quot;direction&quot;: &quot;in&quot;,
      &quot;name&quot;: &quot;req&quot;,
      &quot;methods&quot;: [
        &quot;get&quot;
      ],
      &quot;route&quot;: &quot;message&quot;
    },
    {
      &quot;type&quot;: &quot;http&quot;,
      &quot;direction&quot;: &quot;out&quot;,
      &quot;name&quot;: &quot;res&quot;
    }
  ]
}

```

With the above settings, the API endpoint is:

* Triggered when an HTTP request is made to the function
* Available to all requests regardless of authentication status
* Exposed via the /api/message route

## Run the API locally
Visual Studio Code integrates with Azure Functions Core Tools to let you run this project on your local development computer before you publish to Azure.

&gt;Tip:
Make sure you have all the resources listed in the prerequisites section installed before proceeding.

1. Run the function by pressing F5 to start the Functions app.

2. If Azure Functions Core Tools isn't already *installed*, select **Install** at the prompt.  The Core Tools shows output from the running application in the Terminal panel. As a part of the output, you can see the URL endpoint of your HTTP-triggered function running locally.

![image info](/img/azure/8/create-azure-functions-vscode-2.png)

3. With Core Tools running, navigate to the following URL to verify the API is running correctly: http://localhost:7071/api/message.

The response in the browser should look similar to the following example:

![image info](/img/azure/8/create-azure-functions-vscode-3.png)

4. Press Shift + F5 to stop the debugging session.

## Call the API from the application

When deployed to Azure, requests to the API are automatically routed to the Functions app for requests sent to the api route. Working locally, you have to configure the application settings to proxy requests to the local API.

## Local proxy
You can configure a proxy for the Live Server Visual Studio Code extension that routes all requests to /api to the running API endpoint at http://127.0.0.1:7071/api.

1. Open the .vscode/settings.json file.

2. Add the following settings to specify a proxy for Live Server.
   
```json

&quot;liveServer.settings.proxy&quot;: {
   &quot;enable&quot;: true,
   &quot;baseUri&quot;: &quot;/api&quot;,
   &quot;proxyUri&quot;: &quot;http://127.0.0.1:7071/api&quot;
}
```

This configuration is best saved in project settings file, as opposed to in the user settings file.

Using project settings assures the proxy isn't applied to all other projects opened in Visual Studio Code.

## Update HTML files to access the API

1. Next, update the content of the index.html file with the following code to fetch the text from the API function and display it on the screen:

```
&lt;!DOCTYPE html&gt;
&lt;html lang=&quot;en&quot;&gt;

&lt;head&gt;
  &lt;meta charset=&quot;UTF-8&quot;&gt;
  &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;
  &lt;link rel=&quot;stylesheet&quot; href=&quot;styles.css&quot;&gt;
  &lt;title&gt;Vanilla JavaScript App&lt;/title&gt;
&lt;/head&gt;

&lt;body&gt;
  &lt;main&gt;
    &lt;h1&gt;Vanilla JavaScript App&lt;/h1&gt;
    &lt;p&gt;Loading content from the API: &lt;b id=&quot;name&quot;&gt;...&lt;/b&gt;&lt;/p&gt;
  &lt;/main&gt;

  &lt;script&gt;
    (async function() {
      let { text } = await( await fetch(`/api/message`)).json();
      document.querySelector('#name').textContent = text;
    }())
  &lt;/script&gt;
&lt;/body&gt;

&lt;/html&gt;
```

2. Press **F5** to start the API project.

3. Press **F1** and choose *Live Server: Open with Live Server*.

You should now see the API message in the web page.

![image info](/img/azure/8/create-azure-functions-vscode-4.png)

&gt;Note:You can use other HTTP servers or proxies to serve the index.html file. Accessing the index.html from file:/// will not work.

4. Press Shift + F5 to stop the API project.

## Commit and push your changes to GitHub
Using Visual Studio Code, commit and push your changes to the remote git repository.

1. Press **F1** to open the Command Palette
2. Type **Git: Commit All**
3. Add a commit message and press **Enter**
4. Press **F1**
5. Type in **Git: push** and press **Enter**

## Create a static web app
1. Navigate to the [Azure portal](https://portal.azure.com/)
2. Click **Create a Resource**
3. Search for **Static Web App**
4. Click **Static Web App (Preview)**
5. Click **Create**
   
Next, add the app-specific settings.

1. Select your *Azure subscription*
2. Select or *create a new Resource Group*
3. Name the app **my-vanilla-api**.
4. Select *Region* closest to you
5. Select the **Free** SKU
6. Click the **Sign-in with GitHub** button and authenticate with GitHub
7. Select your preferred *Organization*
8. Select **my-vanilla-api** from the Repository drop-down
9. Select **master** from the Branch drop-down
10. Click the **Next: Build &gt;** button to edit the build configuration
    
Next, add the following the build details.

1. Enter **/** for the App location.

2. Enter **api** in the Api location box.

3. Clear the default value out of the *App artifact location*, leaving the box empty.

4. Click **Review + create**.

5. Click the **Create** button

Once you click the *Create* button, Azure does two things. First, the underlying cloud services are created to support the app. Next, a background process begins to build and deploy the application.

6. Click the **Go to Resource** button to take you to the web app's *Overview* page.

As the app is being built in the background, you can click on the banner which contains a link to view the build status.

![image info](/img/azure/8/static-app-url-from-portal.png)


## Clean up resources

If you don't want to keep this application for further use, you can use the following steps to delete the Azure Static Web App and its related resources.

1. Navigate to the [Azure portal](https://portal.azure.com/)
2. In the top search bar, type **Resource groups**
3. Click **Resource groups**
4. Select **myResourceGroup**
5. On the *myResourceGroup* page, make sure that the listed resources are the ones you want to delete.
6. Select **Delete**
7. Type **myResourceGroup** in the text box
8. Select **Delete**.</content><author><name>Girish Godage</name></author><category term="learning" /><summary type="html">Introduction</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/img/AzureAppSerive.png" /></entry><entry><title type="html">How to build your own AI personal assistant using Python</title><link href="http://localhost:4000/blog/pythonPA" rel="alternate" type="text/html" title="How to build your own AI personal assistant using Python" /><published>2020-10-10T10:10:10+00:00</published><updated>2020-10-10T10:10:10+00:00</updated><id>http://localhost:4000/blog/PythonPersonalAssistant</id><content type="html" xml:base="http://localhost:4000/blog/pythonPA">## How to build your own AI personal assistant using Python

*An AI personal assistant is a piece of software that understands verbal or written commands and completes task assigned by the client. It is an example of weak AI that is it can only execute and perform quest designed by the user.*

![image info](/img/G1.png)

Want to build your own personal AI assistant like Apple Siri, Microsoft Cortana and Google assistant?

You can check out this Article to build one in a few simple steps!

With the python programming language, a script most commonly used by the developers can be used to build your personal AI assistant to perform task designed by the users.

Now, let’s write a script for our personal voice assistant using python.

## Skills:

The implemented voice assistant can perform the following task it can **open YouTube, Gmail, Google chrome and stack overflow. Predict current time, take a photo, search Wikipedia to abstract required data, predict weather in different cities, get top headline news from Times of India and can answer computational and geographical questions too**.

The following queries of the voice assistant can be manipulated as per the users need.

## Packages required:

To build a personal voice assistant it’s necessary to install the following packages in your system using the pip command.

1) **Speech recognition** — Speech recognition is an important feature used in house automation and in artificial intelligence devices. The main function of this library is it tries to understand whatever the humans speak and converts the speech to text.
   
2) **pyttsx3** — pyttxs3 is a text to speech conversion library in python. This package supports text to speech engines on Mac os x, Windows and on Linux.

3) **wikipedia** — Wikipedia is a multilingual online encyclopedia used by many people from academic community ranging from freshmen to students to professors who wants to gain information over a particular topic. This package in python extracts data’s required from Wikipedia.
   
4) **ecapture** — This module is used to capture images from your camera
   
5) **datetime** — This is an inbuilt module in python and it works on date and time
   
6) **os** — This module is a standard library in python and it provides the function to interact with operating system

7) **time** — The time module helps us to display time
   
8) **Web browser** — This is an in-built package in python. It extracts data from the web
   
9)  **Subprocess** — This is a standard library use to process various system commands like to log off or to restart your PC.
    
10) **Json**- The json module is used for storing and exchanging data.
    
11) **requests**- The request module is used to send all types of HTTP request. Its accepts URL as parameters and gives access to the given URL’S.
    
12) **wolfram alpha** — Wolfram Alpha is an API which can compute expert-level answers using Wolfram’s algorithms, knowledge base and AI technology. It is made possible by the Wolfram Language

## Implementation:
*Import the following libraries*

```code

import speech_recognition as sr
import pyttsx3
import datetime
import wikipedia
import webbrowser
import os
import time
import subprocess
from ecapture import ecapture as ec
import wolframalpha
import json
import requests
```

## Setting up the speech engine:

The pyttsx3 module is stored in a variable name engine.
**Sapi5** is a **Microsoft Text to speech engine used for voice recognition**.

The voice Id can be set as either 0 or 1,
- 0 indicates Male voice
- 1 indicates Female voice

```code
engine=pyttsx3.init('sapi5')
voices=engine.getProperty('voices')
engine.setProperty('voice','voices[0].id')

```

Now define a function **speak** which converts text to speech. The speak function takes the text as its argument,further initialize the engine.

**runAndWait**: This function Blocks while processing all currently queued commands. It Invokes callbacks for engine notifications appropriately and returns back when all commands queued before this call are emptied from the queue.

```
def speak(text):
    engine.say(text)
    engine.runAndWait()
```

## Initiate a function to greet the user:

Define a function wishMe for the AI assistant to greet the user.

The **now().hour** function abstract’s the hour from the current time.

If the hour is greater than zero and less than 12, the voice assistant wishes you with the message “Good Morning”.

If the hour is greater than 12 and less than 18, the voice assistant wishes you with the following message “Good Afternoon”.

Else it voices out the message “Good evening”

```
def wishMe():
    hour=datetime.datetime.now().hour
    if hour&gt;=0 and hour&lt;12:
        speak(&quot;Hello,Good Morning&quot;)
        print(&quot;Hello,Good Morning&quot;)
    elif hour&gt;=12 and hour&lt;18:
        speak(&quot;Hello,Good Afternoon&quot;)
        print(&quot;Hello,Good Afternoon&quot;)
    else:
        speak(&quot;Hello,Good Evening&quot;)
        print(&quot;Hello,Good Evening&quot;)
```

## Setting up the command function for your AI assistant :

Define a function takecommand for the AI assistant to understand and to accept human language. The microphone captures the human speech and the recognizer recognizes the speech to give a response.

The exception handling is used to handle the exception during the run time error and,the recognize_google function uses google audio to recognize speech.

```
def takeCommand():
    r=sr.Recognizer()
    with sr.Microphone() as source:
        print(&quot;Listening...&quot;)
        audio=r.listen(source)

        try:
            statement=r.recognize_google(audio,language='en-in')
            print(f&quot;user said:{statement}\n&quot;)

        except Exception as e:
            speak(&quot;Pardon me, please say that again&quot;)
            return &quot;None&quot;
        return statement

print(&quot;Loading your AI personal assistant G-One&quot;)
speak(&quot;Loading your AI personal assistant G-One&quot;)
wishMe()
```

## The Main function:
The main function starts from here,the commands given by the humans is stored in the variable **statement**.

```
if __name__=='__main__':


    while True:
        speak(&quot;Tell me how can I help you now?&quot;)
        statement = takeCommand().lower()
        if statement==0:
            continue
```

If the following trigger words are there in the statement given by the users it invokes the virtual assistant to speak the below following commands.

```
if &quot;good bye&quot; in statement or &quot;ok bye&quot; in statement or &quot;stop&quot; in statement:
            speak('your personal assistant G-one is shutting down,Good bye')
            print('your personal assistant G-one is shutting down,Good bye')
            break
```

## Skill 1 -Fetching data from Wikipedia:

The following commands helps to extract information from wikipedia. The **wikipedia.summary()** function takes two arguments, the statement given by the user and how many sentences from wikipedia is needed to be extracted is stored in a variable **result**.

```
if 'wikipedia' in statement:
            speak('Searching Wikipedia...')
            statement =statement.replace(&quot;wikipedia&quot;, &quot;&quot;)
            results = wikipedia.summary(statement, sentences=3)
            speak(&quot;According to Wikipedia&quot;)
            print(results)
            speak(results)

```
## Skill 2 -Accessing the Web Browsers — Google chrome , G-Mail and YouTube:

The web browser extracts data from web. The **open_new_tab** function accepts **URL** as a parameter that needs to be accessed.

The **Python time sleep function** is used to add delay in the execution of a program. We can use this function to halt the execution of the program for given **time** in seconds.

```
elif 'open youtube' in statement:
            webbrowser.open_new_tab(&quot;https://www.youtube.com&quot;)
            speak(&quot;youtube is open now&quot;)
            time.sleep(5)

        elif 'open google' in statement:
            webbrowser.open_new_tab(&quot;https://www.google.com&quot;)
            speak(&quot;Google chrome is open now&quot;)
            time.sleep(5)

        elif 'open gmail' in statement:
            webbrowser.open_new_tab(&quot;gmail.com&quot;)
            speak(&quot;Google Mail open now&quot;)
            time.sleep(5)

```

## Skill 3 -Predicting time:

The current time is abstracted from **datetime.now()** function which displays the hour, minute and second and is stored in a variable name **strTime**.

```
elif 'time' in statement:
            strTime=datetime.datetime.now().strftime(&quot;%H:%M:%S&quot;)
            speak(f&quot;the time is {strTime}&quot;)
```

## Skill 4 -To fetch latest news:
If the user wants to know the latest news , The voice assistant is programmed to fetch top headline news from Time of India by using the web browser function.

## Skill 5 -Capturing photo:

**The ec.capture()** function is used to capture images from your camera. It accepts 3 parameter.

**Camera index** — The first connected webcam will be indicated as index 0 and the next webcam will be indicated as index 1.

**Window name** — It can be a variable or a string. If you don’t wish to see the window, type as False.

**Save name** — A name can be given to the image and if you don’t want to save the image, type as false.

```
elif 'news' in statement:
            news = webbrowser.open_new_tab(&quot;https://timesofindia.indiatimes.com/home/headlines”)
            speak('Here are some headlines from the Times of India,Happy reading')
            time.sleep(6)

        elif &quot;camera&quot; in statement or &quot;take a photo&quot; in statement:
            ec.capture(0,&quot;robo camera&quot;,&quot;img.jpg&quot;)
```

## Skill 6-Searching data from web:

From the **web browser** you can search required data by passing the user statement (command) to the **open_new_tab()** function.

**User**: Hey G-One, please search images of butterfly

The Voice assistant opens the google window &amp; fetches butterfly images from web.

```
elif 'search'  in statement:
            statement = statement.replace(&quot;search&quot;, &quot;&quot;)
            webbrowser.open_new_tab(statement)
            time.sleep(5)	
```

## Skill 7- Setting your AI assistant to answer geographical and computational questions:

Here we can use a third party API called **Wolfram alpha API** to answer computational and geographical questions.It is made possible by the Wolfram Language. The **client** is an instance (class) created for wolfram alpha. The **res** variable stores the response given by the wolfram alpha.

```
elif 'ask' in statement:
            speak('I can answer to computational and geographical questions  and what question do you want to ask now')
            question=takeCommand()
            app_id=&quot;Paste your unique ID here &quot;
            client = wolframalpha.Client('R2K75H-7ELALHR35X')
            res = client.query(question)
            answer = next(res.results).text
            speak(answer)
            print(answer)
```

To access the wolfram alpha API an unique App ID is required which can be generated by the following ways:

1. Login to the official page of wolfram alpha and create an account if you do not possess one.

![image info](/img/python/datascience/img/6/1.png)

2. Sign in using your wolfram ID

![image info](/img/python/datascience/img/6/2.png)


3. Now you will view the homepage of the website. Head to the account section in the top right corner where you see your email. In the drop down menu, select the My Apps (API) option.

![image info](/img/python/datascience/img/6/3.png)

4. You will see this following window, now click Get APP_ID button

![image info](/img/python/datascience/img/6/4.png)

5. Now you will get the following dialog box, give a suitable name and description and click the App ID button, an App ID will be generated and this is an unique ID. Using the App Id use can access the Wolfram alpha API.

![image info](/img/python/datascience/img/6/5.png)


**Human:** Hey G-One ,what is the capital of California?

**G-One Voice assistant:** Sacramento, United States of America


## Skill 8- Extra features:

It would be interesting to program your AI assistant to answer the following questions like what it can and who created it,isn't it?

```
elif 'who are you' in statement or 'what can you do' in statement:
            speak('I am G-one version 1 point O your personal assistant. I am programmed to minor tasks like'
                  'opening youtube,google chrome, gmail and stackoverflow ,predict time,take a photo,search wikipedia,predict weather' 
                  'In different cities, get top headline news from times of india and you can ask me computational or geographical questions too!')


        elif &quot;who made you&quot; in statement or &quot;who created you&quot; in statement or &quot;who discovered you&quot; in statement:
            speak(&quot;I was built by Girish&quot;)
            print(&quot;I was built by Girish&quot;)
```
## Skill 9- To forecast weather:

Now to program your AI assistant to detect weather we need to generate an API key from Open Weather map.

Open weather map is an online service which provides weather data. By generating an API ID in the official website you can use the APP_ID to make your voice assistant detect weather of all places whenever required. The necessary modules needed to be imported for this weather detection is json and request module.

The **city_name variabl**e takes the command given by the human using the **takeCommand()** function.

The **get** method of **request** module returns a **response** object. And the **json** methods of response object converts json format data into python format.

The variable **X** contains list of nested dictionaries which checks whether the value of ‘COD’ is 404 or not that is if the city is found or not.

The values such as temperature and humidity is stored in the main key of variable **Y**.

```
elif &quot;weather&quot; in statement:
            api_key=&quot;Apply your unique ID&quot;
            base_url=&quot;https://api.openweathermap.org/data/2.5/weather?&quot;
            speak(&quot;what is the city name&quot;)
            city_name=takeCommand()
            complete_url=base_url+&quot;appid=&quot;+api_key+&quot;&amp;q=&quot;+city_name
            response = requests.get(complete_url)
            x=response.json()
            if x[&quot;cod&quot;]!=&quot;404&quot;:
                y=x[&quot;main&quot;]
                current_temperature = y[&quot;temp&quot;]
                current_humidiy = y[&quot;humidity&quot;]
                z = x[&quot;weather&quot;]
                weather_description = z[0][&quot;description&quot;]
                speak(&quot; Temperature in kelvin unit is &quot; +
                      str(current_temperature) +
                      &quot;\n humidity in percentage is &quot; +
                      str(current_humidiy) +
                      &quot;\n description  &quot; +
                      str(weather_description))
                print(&quot; Temperature in kelvin unit = &quot; +
                      str(current_temperature) +
                      &quot;\n humidity (in percentage) = &quot; +
                      str(current_humidiy) +
                      &quot;\n description = &quot; +
                      str(weather_description))

```

**Human:** Hey G-One ,I want to get the weather data

**G-One:** What is the city name?

**Human:** Himachal Pradesh

**G-One:** Temperature in kelvin unit is 301.09 , Humidity in percentage is 52 and Description is light rain.

## Skill 10- To log off your PC:

The subprocess.call() function here is used to process the system function to log off or to turn off your PC. This invokes your AI assistant to automatically turn off your PC.

```
    elif &quot;log off&quot; in statement or &quot;sign out&quot; in statement:
            speak(&quot;Ok , your pc will log off in 10 sec make sure you exit from all applications&quot;)
            subprocess.call([&quot;shutdown&quot;, &quot;/l&quot;])
			
    time.sleep(3)

```

Hurray , We have finally built our own AI voice assistant . Further you can still add more functionalities to your AI voice assistant to perform more task.

Check out my GitHub profile for code:

https://github.com/girishgodage/ai-personal-assistant

Happy Coding !!</content><author><name>Girish Godage</name></author><category term="learning" /><summary type="html">How to build your own AI personal assistant using Python</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/img/G1.png" /></entry></feed>